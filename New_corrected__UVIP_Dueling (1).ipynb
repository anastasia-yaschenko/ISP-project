{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_corrected__UVIP_Dueling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7849fb77569487993ff855128fe8be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c72ed20bf914870974f928970a54c94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb674fa1a005428b98a61b7e5418cbc9",
              "IPY_MODEL_999e2731cd6e426faf0b4edc497127de",
              "IPY_MODEL_0e60904671ba44c09e276f906ad2e6df"
            ]
          }
        },
        "6c72ed20bf914870974f928970a54c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb674fa1a005428b98a61b7e5418cbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_caf69b85964a402284e35dd6fbfc28a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95c4d67bb4ac496d885103df4ef86537"
          }
        },
        "999e2731cd6e426faf0b4edc497127de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fde0618e8314c60ab214b2156cd2092",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_921d732a1ccb434ca6878015c1a350de"
          }
        },
        "0e60904671ba44c09e276f906ad2e6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16518440b4d84174a030b17aa06d7064",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [00:07&lt;00:00,  2.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_447785a073524a79a9beabb53822c0d2"
          }
        },
        "caf69b85964a402284e35dd6fbfc28a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95c4d67bb4ac496d885103df4ef86537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fde0618e8314c60ab214b2156cd2092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "921d732a1ccb434ca6878015c1a350de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16518440b4d84174a030b17aa06d7064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "447785a073524a79a9beabb53822c0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9aca35c5cb6b4ab6b1584fb418886294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca50739231e2415abf1d8aa97a5e2f22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bee5a4d363cc4d7dad46005cc797f84b",
              "IPY_MODEL_043a22730f024d4fa6aa3d6cfa78e23f",
              "IPY_MODEL_2d014d4d2b03498b814cd8545d91dda2"
            ]
          }
        },
        "ca50739231e2415abf1d8aa97a5e2f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bee5a4d363cc4d7dad46005cc797f84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07c14e5e14cb4f15955ef90b9b609a73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cc252a0bd524a1e90568a32371e6674"
          }
        },
        "043a22730f024d4fa6aa3d6cfa78e23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_179b44aedcd94ff688a3a3afd9252f18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b20445eddfa4a3c9802082708b0c703"
          }
        },
        "2d014d4d2b03498b814cd8545d91dda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_999521480e894c96b90fa1ed359189c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0f425dae84b49199bbb82358f62edeb"
          }
        },
        "07c14e5e14cb4f15955ef90b9b609a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cc252a0bd524a1e90568a32371e6674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "179b44aedcd94ff688a3a3afd9252f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b20445eddfa4a3c9802082708b0c703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "999521480e894c96b90fa1ed359189c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0f425dae84b49199bbb82358f62edeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bc98bd4ba39454bb170bdb31893908d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_829b09b7118243f3a21a615d1b3ffeeb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3712754bd4464599abdf5f70ef84f754",
              "IPY_MODEL_a1724519925a49f9aef0dec65d7580e3",
              "IPY_MODEL_480fd7ba501f418da6e85c62ee2889b8"
            ]
          }
        },
        "829b09b7118243f3a21a615d1b3ffeeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3712754bd4464599abdf5f70ef84f754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9201252f129549faa400ea3464285ed0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6db0b1b66b604807b6b9625743b69d7d"
          }
        },
        "a1724519925a49f9aef0dec65d7580e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be01ffbabd124c758871cf037a9535a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb6f762e69df41aba8e512a279ab948e"
          }
        },
        "480fd7ba501f418da6e85c62ee2889b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfaff3808d3141a7b79018140c614511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30/30 [00:51&lt;00:00,  1.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93090153d30a4528851de8c1c2f68644"
          }
        },
        "9201252f129549faa400ea3464285ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6db0b1b66b604807b6b9625743b69d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be01ffbabd124c758871cf037a9535a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb6f762e69df41aba8e512a279ab948e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfaff3808d3141a7b79018140c614511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93090153d30a4528851de8c1c2f68644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4AS7njD7iL6",
        "outputId": "9b6ac19a-3db9-4d12-d561-e38e2a92ec4a"
      },
      "source": [
        "#Code for Duel DQN references https://github.com/bhctsntrk/OpenAIPong-DQN#orange_book-using-in-colab\n",
        "#!nvidia-smi\n",
        "!pip install --upgrade gym\n",
        "!pip install 'gym[atari, accept-rom-license]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym) (3.6.0)\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.8.2)\n",
            "Requirement already satisfied: ale-py~=0.7.1 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.7.3)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.1->gym[accept-rom-license,atari]) (5.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.62.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym[accept-rom-license,atari]) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym[accept-rom-license,atari]) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D98CddQuwKG"
      },
      "source": [
        "import gym\n",
        "import cv2\n",
        "\n",
        "\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import tqdm\n",
        "from tqdm import trange\n",
        "import seaborn as sns\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.feature import hog\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from PER import *\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rGMlN2uzgk"
      },
      "source": [
        "ENVIRONMENT = \"PongDeterministic-v4\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_MODELS = True  # Save models to file so you can test later\n",
        "MODEL_PATH = \"pong-cnn-\"  # Models path for saving or loading\n",
        "SAVE_MODEL_INTERVAL = 10  # Save models at every X epoch\n",
        "TRAIN_MODEL = False  # Train model while playing (Make it False when testing a model)\n",
        "\n",
        "LOAD_MODEL_FROM_FILE = True  # Load model from file\n",
        "LOAD_FILE_EPISODE = 900  # Load Xth episode from file\n",
        "\n",
        "BATCH_SIZE = 64  # Minibatch size that select randomly from mem for train nets\n",
        "MAX_EPISODE = 10000  # Max episode\n",
        "MAX_STEP = 10000  # Max step size for one episode\n",
        "\n",
        "MAX_MEMORY_LEN = 50000  # Max memory len\n",
        "MIN_MEMORY_LEN = 40000  # Min memory len before start train\n",
        "\n",
        "GAMMA = 0.97  # Discount rate\n",
        "ALPHA = 0.05  # Learning rate\n",
        "EPSILON_DECAY = 0.98  # Epsilon decay rate by step\n",
        "\n",
        "RENDER_GAME_WINDOW = False  # Opens a new window to render the game (Won't work on colab default)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxF5-bzUu1q-"
      },
      "source": [
        "class DuelCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN with Duel Algo. https://arxiv.org/abs/1511.06581\n",
        "    \"\"\"\n",
        "    def __init__(self, h, w, output_size):\n",
        "        super(DuelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=4,  out_channels=32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "\n",
        "        linear_input_size = convw * convh * 64  # Last conv layer's out sizes\n",
        "\n",
        "        # Action layer\n",
        "        self.Alinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Alrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Alinear2 = nn.Linear(in_features=128, out_features=output_size)\n",
        "\n",
        "        # State Value layer\n",
        "        self.Vlinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Vlrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Vlinear2 = nn.Linear(in_features=128, out_features=1)  # Only 1 node\n",
        "\n",
        "    def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "        \"\"\"\n",
        "        Calcs conv layers output image sizes\n",
        "        \"\"\"\n",
        "        next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "        next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "        return next_w, next_h\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten every batch\n",
        "\n",
        "        Ax = self.Alrelu(self.Alinear1(x))\n",
        "        Ax = self.Alinear2(Ax)  # No activation on last layer\n",
        "\n",
        "        Vx = self.Vlrelu(self.Vlinear1(x))\n",
        "        Vx = self.Vlinear2(Vx)  # No activation on last layer\n",
        "\n",
        "        q = Vx + (Ax - Ax.mean()) \n",
        "\n",
        "        return q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLGIi7sidntu"
      },
      "source": [
        "def get_tensor(samples_traj, mode):\n",
        "  '''\n",
        "  Get rensor from array of sample trajectories\n",
        "  '''\n",
        "  if mode=='original':\n",
        "    samples_tensor_traj = np.zeros((samples_traj.shape[0], samples_traj.shape[1]*samples_traj.shape[2]*samples_traj.shape[3]))\n",
        "    for i in  range(samples_traj.shape[0]):\n",
        "      samples_tensor_traj[i] = samples_traj[i].flatten()\n",
        "  else:\n",
        "    samples_tensor_traj = np.zeros((samples_traj.shape[0], samples_traj.shape[1], samples_traj.shape[2], samples_traj.shape[3]))\n",
        "    for i in  range(samples_traj.shape[0]):\n",
        "      samples_tensor_traj[i] = samples_traj[i]\n",
        "\n",
        "  samples_tensor_traj = torch.tensor(samples_tensor_traj, dtype=torch.float32)\n",
        "  \n",
        "  return samples_tensor_traj\n",
        "\n",
        "def overlay_frames(sample, weight_first, is_np = False):\n",
        "  '''\n",
        "  Stack 4 frames from sample into one with given weight weight_first given to the first combination\n",
        "  is_np == True if numpy array\n",
        "  '''\n",
        "  if is_np == False:\n",
        "    dst = cv2.addWeighted(sample[0].numpy(),weight_first,sample[1].numpy(),1-weight_first,0)\n",
        "    dst = cv2.addWeighted(dst,weight_first,sample[2].numpy(),1-weight_first,0)\n",
        "    dst = cv2.addWeighted(dst,weight_first,sample[3].numpy(),1-weight_first,0)\n",
        "    return dst\n",
        "  dst = cv2.addWeighted(sample[0],weight_first,sample[1],1-weight_first,0)\n",
        "  dst = cv2.addWeighted(dst,weight_first,sample[2],1-weight_first,0)\n",
        "  dst = cv2.addWeighted(dst,weight_first,sample[3],1-weight_first,0)\n",
        "  return dst\n",
        "\n",
        "def value_from_network(s, agent_):\n",
        "  '''\n",
        "  Returns value function predicted by DuelDQN\n",
        "  s - state, agent_ - Agent instance\n",
        "  '''\n",
        "  s = torch.tensor(s, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "  s = F.relu(agent_.online_model.bn1(agent_.online_model.conv1(s)))\n",
        "  s = F.relu(agent_.online_model.bn2(agent_.online_model.conv2(s)))\n",
        "  s = F.relu(agent_.online_model.bn3(agent_.online_model.conv3(s)))\n",
        "  s = s.view(s.size(0), -1)\n",
        "  V_pred = agent_.online_model.Vlrelu(agent_.online_model.Vlinear1(s))\n",
        "  V_pred = agent_.online_model.Vlinear2(V_pred)\n",
        "\n",
        "  return V_pred.detach().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plT51MPbu5U5"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, environment, random_policy):\n",
        "        \"\"\"\n",
        "        Hyperparameters definition for Agent\n",
        "        \"\"\"\n",
        "        # State size for breakout env. SS images (210, 160, 3). Used as input size in network\n",
        "        self.state_size_h = environment.observation_space.shape[0]\n",
        "        self.state_size_w = environment.observation_space.shape[1]\n",
        "        self.state_size_c = environment.observation_space.shape[2]\n",
        "\n",
        "        # Activation size for breakout env. Used as output size in network\n",
        "        self.action_size = environment.action_space.n\n",
        "        self.random_policy = random_policy\n",
        "\n",
        "        # Image pre process params\n",
        "        self.target_h = 80  # Height after process\n",
        "        self.target_w = 64  # Widht after process\n",
        "\n",
        "        self.crop_dim = [20, self.state_size_h, 0, self.state_size_w]  # Cut 20 px from top to get rid of the score table\n",
        "\n",
        "        # Trust rate to our experiences\n",
        "        self.gamma = GAMMA  # Discount coef for future predictions\n",
        "        self.alpha = ALPHA  # Learning Rate\n",
        "\n",
        "        # After many experinces epsilon will be 0.05\n",
        "        # So we will do less Explore more Exploit\n",
        "        self.epsilon = 1  # Explore or Exploit\n",
        "        self.epsilon_decay = EPSILON_DECAY  # Adaptive Epsilon Decay Rate\n",
        "        self.epsilon_minimum = 0.03  # Minimum for Explore\n",
        "\n",
        "        # Replay memory (either prioritized (PER) or ordinary experience replay)\n",
        "        self.USE_PER = True #if to use PER\n",
        "        self.memory = deque(maxlen=MAX_MEMORY_LEN) #ordinary experience replay\n",
        "        self.MEMORY = Memory(MAX_MEMORY_LEN)#prioritized experience replay\n",
        "\n",
        "        # Create two model for DDQN algorithm\n",
        "        self.online_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model.load_state_dict(self.online_model.state_dict())\n",
        "        self.target_model.eval() #do not train target model - evaluation mode\n",
        "\n",
        "        # Adam used as optimizer\n",
        "        self.optimizer = optim.Adam(self.online_model.parameters(), lr=self.alpha)\n",
        "\n",
        "    def storeResults(self, state, action, reward, next_state, done):\n",
        "        '''\n",
        "        Appends experience to memory\n",
        "        '''\n",
        "        experience = state[None, :], action, reward, next_state[None, :], done\n",
        "        if self.USE_PER:\n",
        "            self.MEMORY.store(experience)\n",
        "        else:\n",
        "            self.memory.append([experience])\n",
        "\n",
        "\n",
        "    def preProcess(self, image):\n",
        "        \"\"\"\n",
        "        Process image: crop resize, grayscale and normalize the images\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # To grayscale\n",
        "        frame = frame[self.crop_dim[0]:self.crop_dim[1], self.crop_dim[2]:self.crop_dim[3]]  # Cut 20 px from top\n",
        "        frame = cv2.resize(frame, (self.target_w, self.target_h))  # Resize\n",
        "        frame = frame.reshape(self.target_w, self.target_h) / 255  # Normalize\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Get state and do action\n",
        "        Second option can be selected if explore  - select random action\n",
        "        if exploit ask net for action\n",
        "        \"\"\"\n",
        "        if self.random_policy:\n",
        "            return np.random.choice([0,1,2,3,4,5])\n",
        "        else:\n",
        "            act_protocol = 'Explore' if random.uniform(0, 1) <= self.epsilon else 'Exploit'\n",
        "\n",
        "            if act_protocol == 'Explore':\n",
        "                action = random.randrange(self.action_size) #random action\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    state = torch.tensor(state, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "                    q_values = self.online_model.forward(state)  # (1, action_size)\n",
        "                    action = torch.argmax(q_values).item()  # Returns the indices of the maximum value of all elements\n",
        "\n",
        "            return action\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train neural nets with replay memory\n",
        "        returns loss and max_q val predicted from online_net\n",
        "        \"\"\"\n",
        "        if len(agent.memory) < MIN_MEMORY_LEN:\n",
        "            loss, max_q = [0, 0]\n",
        "            return loss, max_q\n",
        "        # We get out minibatch and turn it to numpy array\n",
        "        if self.USE_PER:\n",
        "          # Sample minibatch from the PER memory\n",
        "          tree_idx, minibatch  = self.MEMORY.sample(BATCH_SIZE)\n",
        "          state = np.zeros((BATCH_SIZE, 4, self.target_h, self.target_w))\n",
        "          next_state = np.zeros((BATCH_SIZE, 4, self.target_h, self.target_w))\n",
        "          action, reward, done = [], [], []\n",
        "          for i in range(BATCH_SIZE):\n",
        "            state[i] = minibatch[i][0]\n",
        "            action.append(minibatch[i][1])\n",
        "            reward.append(minibatch[i][2])\n",
        "            next_state[i] = minibatch[i][3]\n",
        "            done.append(minibatch[i][4])\n",
        "        else:\n",
        "          # Randomly sample minibatch from the deque memory\n",
        "          state, action, reward, next_state, done = zip(*random.sample(self.memory, BATCH_SIZE))\n",
        "          # Concat batches in one array\n",
        "          # (np.arr, np.arr) ==> np.BIGarr\n",
        "          state = np.concatenate(state)\n",
        "          next_state = np.concatenate(next_state)\n",
        "        \n",
        "\n",
        "        # Convert them to tensors\n",
        "        state = torch.tensor(state, dtype=torch.float, device=DEVICE)\n",
        "        next_state = torch.tensor(next_state, dtype=torch.float, device=DEVICE)\n",
        "        action = torch.tensor(action, dtype=torch.long, device=DEVICE)\n",
        "        reward = torch.tensor(reward, dtype=torch.float, device=DEVICE)\n",
        "        done = torch.tensor(done, dtype=torch.float, device=DEVICE)\n",
        "\n",
        "        # Make predictions\n",
        "        state_q_values = self.online_model(state)\n",
        "        next_states_q_values = self.online_model(next_state)\n",
        "        next_states_target_q_values = self.target_model(next_state)\n",
        "\n",
        "        # Find selected action's q_value\n",
        "        selected_q_value = state_q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "        # Get indice of the max value of next_states_q_values\n",
        "        # Use that indice to get a q_value from next_states_target_q_values\n",
        "        # We use greedy for policy So it called off-policy\n",
        "        next_states_target_q_value = next_states_target_q_values.gather(1, next_states_q_values.max(1)[1].unsqueeze(1)).squeeze(1)\n",
        "        # Use Bellman function to find expected q value\n",
        "        expected_q_value = reward + self.gamma * next_states_target_q_value* (1 - done)\n",
        "\n",
        "        # Calc loss with expected_q_value and q_value\n",
        "        loss = (selected_q_value - expected_q_value.detach()).pow(2).mean()\n",
        "        if self.USE_PER:\n",
        "          for i in range(len(minibatch)):\n",
        "              td_loss = np.abs(expected_q_value[i].detach() - selected_q_value[i]) + 1e-5\n",
        "              # Update priority\n",
        "              self.MEMORY.batch_update(tree_idx, td_loss)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, torch.max(state_q_values).item()\n",
        "\n",
        "        \n",
        "    def adaptiveEpsilon(self):\n",
        "        \"\"\"\n",
        "        Adaptive Epsilon means every step\n",
        "        we decrease the epsilon so we do less Explore\n",
        "        \"\"\"\n",
        "        if self.epsilon > self.epsilon_minimum:\n",
        "            self.epsilon *= self.epsilon_decay    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnPiHBsfmsyP"
      },
      "source": [
        "def get_rewards(samples, env_copies, env):\n",
        "    rewards = np.zeros((samples.shape[0], 6)) #6 is number of actions\n",
        "    for num_sample, X in enumerate(samples):\n",
        "        for action in range(6):\n",
        "            env.unwrapped.restore_state(env_copies[num_sample])\n",
        "            _, r, _, _ = env.step(action)\n",
        "            rewards[num_sample, action] = r\n",
        "    return rewards\n",
        "\n",
        "\n",
        "\n",
        "def getBounds(env, agent_rand, agent_pol, N, M1, M2, k, gamma, total_steps):\n",
        "    #sns.set(style=\"darkgrid\")\n",
        "\n",
        "    n_actions = env.action_space.n\n",
        "\n",
        "    # generate Y_states. These are next states for every state from sample for every action (repeated M1 times)\n",
        "    # V_ns = torch.zeros((n_actions, N, M1))\n",
        "    Y_pol = torch.zeros((n_actions, N, M1, 1))\n",
        "    Y_rand = torch.zeros((n_actions, N, M1, 1))\n",
        "    #Y_hogs = []\n",
        "    st = []\n",
        "    v_pol = []\n",
        "    v_rand = []\n",
        "    saved_env = []\n",
        "    s = env.reset()\n",
        "    s = agent_pol.preProcess(s)  # Process image\n",
        "    s = np.stack((s, s, s, s))\n",
        "    saved_environment = env.unwrapped.clone_state(include_rng=True)\n",
        "    for i in tqdm.notebook.tqdm(range(N)):\n",
        "        for action in range(n_actions):\n",
        "            for j in range(M1):\n",
        "                env.reset()\n",
        "                env.unwrapped.restore_state(saved_environment)\n",
        "                next_s, _, _, _ = env.step(action)\n",
        "                next_s = agent_pol.preProcess(next_s)  # Process image\n",
        "                next_s = np.stack((next_s, s[0], s[1], s[2]))\n",
        "                #next_s = overlay_frames(next_s, 0.4, True)\n",
        "                #vector_Y = hog(next_s)\n",
        "                #Y_hogs.append(vector_Y)\n",
        "                Y_pol[action, i, j] = value_from_network(next_s, agent_pol)#torch.from_numpy(vector_Y).float()\n",
        "                Y_rand[action, i, j] = value_from_network(next_s, agent_rand)\n",
        "        env.reset()\n",
        "        env.unwrapped.restore_state(saved_environment)\n",
        "        st.append(s)\n",
        "        v_pol.append(value_from_network(s, agent_pol)) #td_value(state)\n",
        "        v_rand.append(value_from_network(s, agent_rand))\n",
        "        saved_env.append(saved_environment)\n",
        "        action = agent_pol.act(s)  # ATTENTION!!!!!!!!!!!!!!!!!!!agent_.act(s) if non-random, np.random.choice([0,1,2,3,4,5]) if random\n",
        "        next_state, reward, done, info = env.step(action)  # Observe\n",
        "        next_state = agent_pol.preProcess(next_state)  # Process image\n",
        "        next_state = np.stack((next_state, s[0], s[1], s[2]))\n",
        "        s = next_state\n",
        "        saved_environment = env.unwrapped.clone_state(include_rng=True)\n",
        "    \n",
        "    V_pi_pol = torch.from_numpy(np.array(v_pol.copy()))\n",
        "    V_pi_rand = torch.from_numpy(np.array(v_rand.copy()))\n",
        "    #samples = np.array(st.copy())\n",
        "    samples_tensor = get_tensor(np.array(st), 'original')\n",
        "    #N1 = samples.shape[0]\n",
        "\n",
        "    #interpolation of value functions\n",
        "    #train KNN for this\n",
        "    #Preprocess frames\n",
        "    gradient_vectors = []\n",
        "    for i in range(N):\n",
        "        image = overlay_frames(st[i], 0.4, True)\n",
        "        vector = hog(image) #Histogram of oriented gradients as feature vector for frames\n",
        "        gradient_vectors.append(vector)\n",
        "        #distances = euclidean_distances(gradient_vectors, gradient_vectors) #calculate distance between states\n",
        "    #sample_embed = TSNE(1).fit_transform(np.array(gradient_vectors), y = None)\n",
        "    #sample_embed = np.array(gradient_vectors)\n",
        "    neigh = NearestNeighbors(n_neighbors=k, algorithm='auto', leaf_size=100, n_jobs=-1, metric=\"euclidean\")\n",
        "    neigh.fit(gradient_vectors)\n",
        "\n",
        "#   Y_embed = TSNE(1).fit_transform(np.array(Y_hogs), y = None)\n",
        "    #Y_hogs = np.array(Y_hogs)\n",
        "    #all = np.vstack((Y_hogs, sample_embed))\n",
        "    #all_embed = TSNE(2).fit_transform(all, y = None)\n",
        "    #plt.scatter(all_embed[:len(Y_hogs)+1,0], all_embed[:len(Y_hogs)+1, 1], c = 'r')\n",
        "    #plt.scatter(all_embed[len(Y_hogs)+1:, 0], all_embed[len(Y_hogs)+1:, 1], c = 'b')\n",
        "    #plt.show()\n",
        "    \n",
        "    #_, idxes_neigh1 = neigh.kneighbors(torch.flatten(Y, end_dim=2).numpy().tolist())\n",
        "    V_ns_pol = Y_pol.mean(dim=-1).reshape(n_actions, N, M1)#V_pi[torch.tensor(idxes_neigh1)].squeeze().mean(dim=-1).reshape(n_actions, N, M1)\n",
        "    V_ns_rand = Y_rand.mean(dim=-1).reshape(n_actions, N, M1)\n",
        "    V_mean_pol = torch.mean(V_ns_pol, dim=-1, keepdims=True)\n",
        "    V_mean_rand = torch.mean(V_ns_rand, dim=-1, keepdims=True)\n",
        "\n",
        "    V_pi_pol = V_pi_pol.squeeze()\n",
        "    V_pi_rand = V_pi_rand.squeeze()\n",
        "\n",
        "    rewards = get_rewards(np.array(st), saved_env, env) #get rewards for every next action from current state\n",
        "    rewards = torch.tensor(rewards.reshape(n_actions, N, 1))\n",
        "\n",
        "    V_up_pol = (torch.zeros_like(V_pi_pol) + torch.max(V_pi_pol)).squeeze()\n",
        "    V_up_rand = (torch.zeros_like(V_pi_rand) + torch.max(V_pi_rand)).squeeze()\n",
        "    upper_list_pol = [V_up_pol.detach().numpy()]\n",
        "    upper_list_rand = [V_up_rand.detach().numpy()]\n",
        "    norm_list_upper_pol = []\n",
        "    norm_list_upper_rand = []\n",
        "\n",
        "    step = 0\n",
        "    Y_hogs = []\n",
        "    with trange(step, total_steps + 1) as progress_bar:\n",
        "      for step in progress_bar:\n",
        "        Y_pol = torch.zeros((n_actions, N, M2, 1))\n",
        "        Y_rand = torch.zeros((n_actions, N, M2, 1))\n",
        "        Y_approx = torch.zeros((n_actions, N, M2, 3888))\n",
        "        s = env.reset()\n",
        "        s = agent_pol.preProcess(s)  # Process image\n",
        "        s = np.stack((s, s, s, s))\n",
        "        saved_environment = env.unwrapped.clone_state(include_rng=True)\n",
        "        for i in range(N):\n",
        "          for j in range(M2):\n",
        "            for action in range(3):\n",
        "              env.reset()\n",
        "              env.unwrapped.restore_state(saved_environment)\n",
        "              next_s, _, _, _ = env.step(action)\n",
        "              next_s = agent_pol.preProcess(next_s)  # Process image\n",
        "              next_s = np.stack((next_s, s[0], s[1], s[2]))\n",
        "              Y_pol[action, i, j] = value_from_network(next_s, agent_pol)\n",
        "              Y_rand[action, i, j] = value_from_network(next_s, agent_rand)\n",
        "              next_s = overlay_frames(next_s, 0.4, True)\n",
        "              vector_Y = hog(next_s)\n",
        "              Y_hogs.append(vector_Y)\n",
        "              Y_approx[action, i, j] =torch.from_numpy(vector_Y).float()\n",
        "          #st.append(s)\n",
        "          #vval = value_from_network(s, agent_) #td_value(state)\n",
        "          #v.append(vval)\n",
        "          #saved_env.append(saved_environment)\n",
        "          env.reset()\n",
        "          env.unwrapped.restore_state(saved_environment)\n",
        "          action = agent_pol.act(s)  # ATTENTION!!!!!!!!!!!!!!!!!!!agent_.act(s) if non-random, np.random.choice([0,1,2,3,4,5]) if random\n",
        "          next_state, reward, done, info = env.step(action)  # Observe\n",
        "          next_state = agent_pol.preProcess(next_state)  # Process image\n",
        "          next_state = np.stack((next_state, s[0], s[1], s[2]))\n",
        "          saved_environment = env.unwrapped.clone_state(include_rng=True)\n",
        "          s = next_state\n",
        "\n",
        "        _, idxes_neigh2 = neigh.kneighbors(torch.flatten(Y_approx, end_dim=2).numpy().tolist())\n",
        "        \n",
        "        V_k_pol = V_up_pol[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "        V_pi_next_pol = Y_pol.mean(dim=-1).reshape(n_actions, N, M2)\n",
        "        V_k_rand = V_up_rand[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "        V_pi_next_rand = Y_rand.mean(dim=-1).reshape(n_actions, N, M2)#V_pi[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "        #print('-----------------------')\n",
        "        #print(rewards)\n",
        "        #print(V_k)\n",
        "        #print(V_mean)\n",
        "        #print(V_pi_next)\n",
        "        #print('-----------------------')\n",
        "        V_up_pol = (rewards + gamma * (V_k_pol - V_pi_next_pol + V_mean_pol)).max(dim=0)[0].mean(dim=-1)\n",
        "        V_up_rand = (rewards + gamma * (V_k_rand - V_pi_next_rand + V_mean_rand)).max(dim=0)[0].mean(dim=-1)\n",
        "        upper_list_pol.append(V_up_pol.detach().numpy())\n",
        "        upper_list_rand.append(V_up_rand.detach().numpy())\n",
        "      \n",
        "\n",
        "   # with trange(step, total_steps + 1) as progress_bar:\n",
        "    #    for step in progress_bar:\n",
        "#\n",
        "    #        _, idxes_neigh2 = neigh.kneighbors(Y_distances)\n",
        "#\n",
        "    #        V_k = V_up[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "    #        V_pi_next = V_pi[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "\n",
        "     #       V_up = (rewards + gamma * (V_k - V_pi_next + V_mean)).max(dim=0)[0].mean(dim=-1)\n",
        "     #       upper_list.append(V_up.detach().numpy())\n",
        "    #Y_embed = TSNE(1).fit_transform(np.array(Y_hogs), y = None)\n",
        "    #plt.plot(Y_embed)\n",
        "    #plt.show()\n",
        "\n",
        "    return V_up_pol, V_pi_pol, V_up_rand, V_pi_rand#, st, v\n",
        "  \n",
        "  \n",
        "def plotBoundsRandomTraj_old(agent_, env, t, samples, V_pi, V_up, k, gamma=0.9, filename=\"Pong-traj.png\"):\n",
        "    samples_tensor = get_tensor(samples, 'original')\n",
        "    traj, traj_envs, V_mont_traj = get_traj(1, agent_, t)\n",
        "    traj_tensor = get_tensor(traj, 'original')\n",
        "\n",
        "    gradient_vectors = []\n",
        "    for i in range(samples_tensor.shape[0]):\n",
        "        image = overlay_frames(samples[i], 0.4, True)\n",
        "        vector = hog(image)\n",
        "        gradient_vectors.append(vector)\n",
        "\n",
        "    neigh = NearestNeighbors(n_neighbors=k, algorithm='auto', leaf_size=100, n_jobs=-1, metric=\"euclidean\")\n",
        "    neigh.fit(gradient_vectors)\n",
        "\n",
        "    traj_tensor2 = []\n",
        "    for j in range(traj_tensor.shape[0]):\n",
        "      image = overlay_frames(traj[j], 0.4, True)\n",
        "      vector = hog(image)\n",
        "      traj_tensor2.append(vector)\n",
        "\n",
        "\n",
        "    _, idxes_neigh = neigh.kneighbors(traj_tensor2)\n",
        "\n",
        "    V_up_traj = V_up[torch.tensor(idxes_neigh)].mean(dim=-1)\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 7))\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    N_states = samples.shape[0]\n",
        "    lower = V_pi\n",
        "    upper = V_up_traj\n",
        "    upper_plot = np.repeat(upper.reshape(-1, 1), repeats=2, axis=1).reshape(-1)\n",
        "    lower_plot = np.repeat(lower.reshape(-1, 1), repeats=2, axis=1).reshape(-1)\n",
        "    states_plot = np.concatenate((np.arange(N_states).reshape(-1,1),\n",
        "                            (np.arange(N_states)+1).reshape(-1,1)), axis=1).reshape(-1)\n",
        "    plt.fill_between(states_plot, lower_plot, upper_plot, alpha=0.5,\n",
        "            edgecolor='k', linestyle='-', label=\"V_up - V_pi\")\n",
        "    plt.legend(loc=\"upper left\", fontsize=20)\n",
        "    plt.xlabel(\"Trajectory States\", fontsize=20)\n",
        "    plt.plot(states_plot, upper_plot, states_plot, lower_plot, color='b')\n",
        "    plt.plot(states_plot, lower_plot, states_plot, lower_plot, color = 'r')\n",
        "    ax.set_xlim((0,20))\n",
        "    ax.set_ylim((-2,2))\n",
        "    ax.tick_params(axis=\"x\", labelsize=25)\n",
        "    ax.tick_params(axis=\"y\", labelsize=25)\n",
        "    plt.gcf().subplots_adjust(bottom=0.1, left = 0.2)\n",
        "\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxUeKMzM8gSP"
      },
      "source": [
        "\n",
        "def get_traj(n_samples, agent_, t):\n",
        "    env= gym.make(ENVIRONMENT)\n",
        "    states_list = []#trajectories\n",
        "    values_at_states = []#values\n",
        "    environment_copies_list = []#copies of environments when they are at particular state\n",
        "    #plt.figure()\n",
        "    for n in range(n_samples):\n",
        "        for_plot = []\n",
        "        state = env.reset()\n",
        "        state = agent_.preProcess(state)  # Process image\n",
        "        state = np.stack((state, state, state, state))\n",
        "\n",
        "        total_step = 0\n",
        "\n",
        "        while True:\n",
        "            saved_environment = env.unwrapped.clone_state(include_rng=True)\n",
        "            environment_copies_list.append(saved_environment)\n",
        "\n",
        "            states_list.append(state)\n",
        "            state_value = value_from_network(state, agent_) #td_value(state)\n",
        "            values_at_states.append(state_value)\n",
        "            #state_ = torch.tensor(state, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "            #q_vals = (agent.online_model.forward(state_)).cpu()[0].detach().numpy()\n",
        "            #value_at_state = sum(list(map(lambda a: ((a == np.argmax(q_vals))*(1 - agent.epsilon + agent.epsilon/6 ) + (a != np.argmax(q_vals))*(agent.epsilon/6 ))*q_vals[a], range(q_vals.shape[0]) )))\n",
        "            #values_at_state.append(value_at_state)\n",
        "\n",
        "            #environment.unwrapped.restore_state(saved_environment)\n",
        "            action = agent_.act(state)  # Act\n",
        "            next_state, reward, done, info = env.step(action)  # Observe\n",
        "            next_state = agent_.preProcess(next_state)  # Process image\n",
        "            next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "            #xx = overlay_frames(next_state, 0.4, True)\n",
        "            #xx = hog(xx)\n",
        "            #for_plot.append(xx)\n",
        "            # Store the transition in memory\n",
        "            agent_.storeResults(state, action, reward, next_state, done) \n",
        "\n",
        "\n",
        "            state = next_state\n",
        "            total_step += 1\n",
        "            if done or total_step >= t:\n",
        "               # print('Episode ends. Total steps made:', total_step)\n",
        "                #embed = TSNE(1).fit_transform(np.array(for_plot), y = None)\n",
        "                #plt.plot(embed)\n",
        "                #plt.show()\n",
        "                break\n",
        "\n",
        "    samples = np.array(states_list)\n",
        "    values_at_states = np.array(values_at_states)\n",
        "  #return torch.FloatTensor(np.vstack(samples)), environment_copies_list, torch.FloatTensor(np.vstack(values_at_states))\n",
        "    return samples, environment_copies_list,  torch.from_numpy(values_at_states) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qxHgFYqZ9Pb"
      },
      "source": [
        "#create non-random agent\n",
        "environment = gym.make(ENVIRONMENT) #Monitor(gym.make(ENVIRONMENT),'./video', force=True)  # Get env\n",
        "agent_policy = Agent(environment, random_policy = False)  # Create Agent\n",
        "LOAD_MODEL_FROM_FILE = True\n",
        "LOAD_FILE_EPISODE = 900\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent_policy.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\", map_location=torch.device('cpu')))\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent_policy.epsilon = param.get('epsilon')\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "else:\n",
        "    startEpisode = 1\n",
        "\n",
        "#create random agent\n",
        "agent_random = Agent(environment, random_policy = True)\n",
        "LOAD_MODEL_FROM_FILE = True\n",
        "LOAD_FILE_EPISODE = 480\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent_random.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\", map_location=torch.device('cpu')))\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent_random.epsilon = param.get('epsilon')\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "else:\n",
        "    startEpisode = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBfxKp94LC3Z"
      },
      "source": [
        "#t = 10\n",
        "#n_samples = 3\n",
        "#samples, _, _ = get_traj(n_samples, agent, t = t)\n",
        "#samples.shape\n",
        "#_, _, V_pi_rand = get_traj_random(n_samples, agent, t = t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8bc98bd4ba39454bb170bdb31893908d",
            "829b09b7118243f3a21a615d1b3ffeeb",
            "3712754bd4464599abdf5f70ef84f754",
            "a1724519925a49f9aef0dec65d7580e3",
            "480fd7ba501f418da6e85c62ee2889b8",
            "9201252f129549faa400ea3464285ed0",
            "6db0b1b66b604807b6b9625743b69d7d",
            "be01ffbabd124c758871cf037a9535a2",
            "fb6f762e69df41aba8e512a279ab948e",
            "dfaff3808d3141a7b79018140c614511",
            "93090153d30a4528851de8c1c2f68644"
          ]
        },
        "id": "FpAgMPunB6eo",
        "outputId": "14731ea5-b228-4186-9e7f-8fe5f5d530df"
      },
      "source": [
        "#n_samples = 1\n",
        "#t = 10\n",
        "#samples, env_copy, V_pi = get_traj(n_samples, agent, t = t)\n",
        "#V_up, samples, V_pi = getBounds(50, samples, env_copy, agent, environment, V_pi, 0.99, 7, 7, 3)\n",
        "valup_pol,val_pol, valup_rand, val_rand = getBounds(environment, agent_random, agent_policy, 30, 20, 20, 3, 0.99, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bc98bd4ba39454bb170bdb31893908d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [05:26<00:00, 29.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdQALV5NnM-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "450df395-4be9-49c7-f862-b9e3fa55a402"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 7))\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.plot(val_pol, c = 'r', label='V_pi')\n",
        "plt.plot(valup_pol, c = 'b', label = 'V_up')\n",
        "plt.title('Non-random')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Value')\n",
        "plt.ylim(-4, 10)\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "0i0SpnhIfM6s",
        "outputId": "b3890d63-ff5a-4130-e853-2679502aad41"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 7))\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.plot(val_rand, c = 'r', label='V_pi')\n",
        "plt.plot(valup_rand, c = 'b', label = 'V_up')\n",
        "plt.title('Random')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Value')\n",
        "plt.ylim(-4, 10)\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4HYYYYLnX9b",
        "outputId": "616a3a05-6fda-4798-e743-9e77ed00765d"
      },
      "source": [
        "len(V_up_rand)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "e7849fb77569487993ff855128fe8be2",
            "6c72ed20bf914870974f928970a54c94",
            "cb674fa1a005428b98a61b7e5418cbc9",
            "999e2731cd6e426faf0b4edc497127de",
            "0e60904671ba44c09e276f906ad2e6df",
            "caf69b85964a402284e35dd6fbfc28a6",
            "95c4d67bb4ac496d885103df4ef86537",
            "4fde0618e8314c60ab214b2156cd2092",
            "921d732a1ccb434ca6878015c1a350de",
            "16518440b4d84174a030b17aa06d7064",
            "447785a073524a79a9beabb53822c0d2"
          ]
        },
        "id": "Oxjb0LX8CCXC",
        "outputId": "55c38ea1-f143-41d9-a8bf-675818716964"
      },
      "source": [
        "n_samples = 10\n",
        "t = 3\n",
        "samples, env_copy, V_pi = get_traj(n_samples, agent, t = t)\n",
        "V_up_rand, samples_rand, V_pi_rand = getBounds_random(20, samples, env_copy, agent, environment, V_pi, 0.99, 5, 5, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7849fb77569487993ff855128fe8be2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [02:08<00:00,  4.15s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5maaHZrqy9M",
        "outputId": "1fe72321-9e1a-4561-bd38-afebd729b863"
      },
      "source": [
        "len(V_pi_rand)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "FE2R6SJof-sv",
        "outputId": "92e18872-4ad4-4018-da71-828aea5eff8d"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 7))\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.plot(V_pi_rand[:31], c = 'r', label = 'V_pi')\n",
        "plt.plot(V_up_rand, c = 'b', label = 'V_up')\n",
        "plt.title('Random')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff9371912d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAG/CAYAAAC5a7XsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b0//tfnzMyZkIRAEgIE2kpFQSoKaKq3FXApXNmF9uEttnirotVau1hAUety5VZFy/VWLq0Pa4UuKH7rghYBoRaXFsWmVaBCrfoDRRKWkEA25sxyPr8/Zs6ZDEmGyeQsM3Nez8cDSWYmwyfHmfOa92c7QkopQURERJ6guN0AIiIicg6Dn4iIyEMY/ERERB7C4CciIvIQBj8REZGHMPiJiIg8hMFPRLZbvnw5Fi5c6HYziAiA3+0GEJF7LrnkEjQ0NMDn86G4uBgTJkzAnXfeiZKSErebRkQ2YcVP5HGPPvoo3nnnHaxduxa7du3CY4895naTiMhGDH4iAgBUVVVh/Pjx2L17NwDgsccew6RJkzBu3DhMmzYNmzdvNh/73HPP4YorrsDSpUvxxS9+EZdccglee+018/59+/Zh3rx5GDduHK6++mo0NTWl/FuvvPIKpk+fjpqaGlx55ZX46KOPzPsuueQSPP7445g5cybGjh2L22+/HQ0NDbj22msxbtw4XHXVVTh27JjNR4OocDH4iQgAcODAAbzxxhv43Oc+BwD47Gc/i9WrV+Nvf/sbbrrpJixatAiHDh0yH79jxw58/vOfx1tvvYVrr70Wd9xxB4wdwBcuXIgzzzwT27Ztw4033ojnn3/e/Lk9e/ZgwYIFuP322/Hmm29i4sSJuOGGGxAOh83HbNq0CStXrsTLL7+MLVu24LrrrsOPfvQjvPXWW9B1Hb/97W8dOipEhYfBT+Rx3/3udzFu3DhceOGFqKiowPe//30AwNSpUzFo0CAoioJp06bhlFNOwY4dO8yfGzJkCP7jP/4DPp8Pc+bMweHDh9HQ0IC6ujrs3LkTP/jBD6CqqtkjYFi/fj0uvPBCXHDBBQgEApg/fz5CoRDeeecd8zHz5s3DgAEDMGjQINTU1ODss8/GF77wBQSDQUyePBm7du1y7gARFRhO7iPyuBUrVuDLX/4y3n77bSxYsABNTU0oKyvD2rVrsXLlSuzfvx8A0N7entJlP2DAAPPrPn36pDymrKwMxcXF5v1DhgxBfX09AODQoUMYMmSIeZ+iKKiursbBgwe7fO5gMJjyfVFREdrb26369Yk8hxU/EQEAzjvvPHz1q1/F0qVLsX//fvz4xz/GnXfeiW3btqG2thann356Rs9TVVWF5ubmlHCuq6szvx44cGDK91JK1NfXY9CgQdb9MkTULQY/EZm+9a1vYevWrWhpaYEQAhUVFQCAZ599Fh988EFGzzF06FCMHj0ay5cvRzgcRm1tLbZs2WLeP3XqVLz22mt48803EYlE8MQTT0BVVYwbN86W34mIUrGrn4hMFRUVuOyyy7BixQpcc801mDt3LoQQmD17Ns4555yMn2fZsmW49dZbcf7552Ps2LGYPXs2mpubAQCnnnoqHnroISxZsgQHDx7EqFGj8Oijj0JVVbt+LSLqQEhjGi4REREVPHb1ExEReQiDn4iIyEMY/ERERB7C4CciIvIQBj8REZGHMPiJiIg8xDPr+Jua2qDr1qxcrKwsxZEjrZY8VyHg8UjF45HEY5GKxyOJxyKVlcdDUQTKy0u6vd8zwa/r0rLgN56Pkng8UvF4JPFYpOLxSOKxSOXU8WBXPxERkYcw+ImIiDyEwU9EROQhDH4iIiIPYfATERF5CIOfiIjIQxj8REREHsLgJyIi8hAGPxERkYcw+ImIiDyEwU9EROQhDH4iIiIPYfATERF5SN5cnW/Pnj1YvHgxjh49iv79+2Pp0qUYNmyY282yVeTwYRx74zX4+vVDYEBV4s8AKMGg203LaVJKxFpaEGloQPRIA6LNx+Dr2xeB8gr4+5fD178/lEDA7WbmPBmNQg+FEDveDhnSoBQVwde3L0QwCCGE282jPCKlhIxEoIdC0I8fh66FcOyQgvYjLZCxKGQ0BhmLAbH438YfxKLxr6Ox+ONiMUDXIXUdSPyRUoeMJb6XyftS/pYSECL+uhUKIASgnPC9AMQJ9yl9iuGvqIC/vByB8kr4KyqgFBfn/etfSCnz4rqI//mf/4mvfe1ruOyyy/DCCy/g2WefxW9+85uMf/7IkVZLLnn4l5312PbPQ4iEY71+rpMJHzyI6LGmTrcLnw8iEIDwq1ACgfjX5h9//MVrKwkZjcbfyNEo/IpATAegCEBR4v++IiAUJf6mUoTlbZKx+L8vIxHoib9lJAIZjUBGopBST/vzwueD8Acg/P4OfxLHz/he8WXVtoDq69XrQ0od0KV5UkuexKT5ffw+CUgAKecgYX4vOt7W8QYpIXXjZBnrcIJMnFRjyRNqV4QQgM8fP4aJP/D5IHx+CH/H730IBFVEo7EO7erYvg639UrH97X1J+T4cU79c8FZgzDh3GE9fq6qqr44fLjF8jaeSNu3D1rdp/H2Ah0OUer3ydN/h9s7ve6Sr7/uglVGImag66FQMuCNr0PH469bK4jEeUZRuv9bKBA+JeV8BJl4b0mZ+F1k8nspIRO/X/z2+PtPD4U6tVsEg/Eiorwi/qGgoiL+fUU5/OWV8Jf3hwio8feGkvl5z8rXhqIIVFaWdnt/XlT8R44cwa5du7By5UoAwIwZM7BkyRI0NjaioqLC5dbZJ9bWCl9JKdTBgzsHXCQCqYUQbWvBiZ/d4idgf4eTcuLrE07K5v0nnCyl1BP/RjQRpEaoRuNtiEbR8WQbzvD3Md+QSuJTNjr+0yecsLu7XY/F29Lpd04EuRqEr6Q08cEo8WHI74tXDcbvE42m/NFDx+OVRNethkgJrK7/7hhimkBq+zp93pTJ/5rn3Q4nVYcIoQA+Jf4BR0n87Veh+DqeRH3xxwgl8WGhQxVm/ImE43930fZQ5q1JHudOEsfrxPDK5LlEx/9Pnf9fQYjkif+EcI//P+z632r456uQ4xb16MTulOMffoB9Dz0AdPuatlAiaEUgAKWoD5SiIih9iqAE+8Bf1i/+dVFR8j7j6z5FKB9YjmOt4RPOVb7O5y2fz3yMGewOkbqO6LFjiDYeQbSpEdHGRkSamszv297bidixYx1fnKmE6OJ36eIc7PMjMuliBP5toiO/V14Ef319PQYNGgSfL16B+Xw+DBw4EPX19Y4H/wVnVWP2JSNs/9Qe+uRjfLLlEQy66hr0G39et48zX5gNhxFpOIxIQwMiDQ2INR9DrLUVsaYWxFpb4p9cuyIElOJi+Er7QlEDiDQ1QW9tTX2MosS7uioHwF9dEf+7shKBikr4KyoxYFA/NNQ3Qtc0yHAYuqZBD2uQmgZdC0OGtfhtmgYZDpmPk5AdKpLUr6WRisZtevwkrBQXIzBgAAKVVfAn/g5UVkIpKurN4YYeCSN69CiiTU2IHm1CtKkJ+vHjHboKT6iET6yMje+ljmAwAC0cRTKA4se504cGIZIh5PNBCRZBCQahBIMQwaD5vUjcduJ9QlUhhEgNLPP4Gd8negWMMIOE8PmgFPWx/ASqRyLx11xLc+LvFpT4JVqa2zOuHOO3y8QhM46TzzyG8ds6/AFSfg+p6/HuYvPv+B/E9JS/ZSx5v1B88Z4enx8i4Ad8fih+P5DSG5TsFWrfvQuttbshIxGIHBt2ix5tQt0v/g+BikoMufF7EMaQVscPVcaLsmPPS4fvU6rmxAfAZEWd6L2zIID7V/VFxIHej94QioJAeTkC5eXdPkZGo4kPB42INB1B7OhR6JFI98MWsS6GNaIx+Iqcey3lRfBbIV23Rzaqqvpa+nwn2ven3YAQ+NzFF0Dtf5J/a1A/YMTn0j5Ej0QQaW5GtLkFkeZmRJpbEG0+hojx/bFm6GENwTNHIVhVFf8zsArBAQOgVpQnega695nBg3v6K+aeIZVut6AAdP4gXgCvjBT1L/nRWvs2KvoGEOjX8/OAXecOPRLBzgd/DqlpOHPJPSg5Jf05IRfYfR51THU5gGFutyJjeRH81dXVOHjwIGKxGHw+H2KxGA4dOoTq6uqMn8OqMX7AmXG6g1u3oejzn8exiA+w7N9SgdLK+J8h8f/5fgB9unm0lviDxva0z+rUuGW+4PFIKsRj0RaOn0cO1zciEO5Z1WvX8ZBS4uCvV6L1Xx+g+js3ob24HO05ftwL8bXRG06O8efeAFUXKisrMWrUKKxbtw4AsG7dOowaNapgx/ejx45C27sHJWePdbspRHQCRVUBALqW6ewW+x17dQua//w6KqbPRN9za9xuDuW4vKj4AeCee+7B4sWL8fOf/xxlZWVYunSp202yTduO7QCA0jHjXG4JEZ1IJIJfhnMj+Nv/9T4OrVmNkrPORuVlc9xuDuWBvAn+4cOH4/e//73bzXBE6/Z34a+ogPqZz7jdFCI6gbGPhh7WXG4JEGlsRP0vViAwYAAGX3d9Tq4yoNzDV0mO0SNhtO96DyVjxub9JhFEhShXKn49Ekbdz5dDD4cx5Lvfh6+4xNX2UP5g8OeY9t27IcNhlI7h+D5RLjLH+F0MfiklDv32N9D27kH1tdchOGSoa22h/MPgzzFt29+FCAbRZ+QZbjeFiLqQrPjd6+o/uuUVNG/9MypmXobScee61g7KTwz+HCKlRNuO7Sj5wmgoAdXt5hBRF4RqjPG7U/G3v/9PHF7zJErGjEXlzMtcaQPlNwZ/DtH2fYJoUyNK2M1PlLMUF8f4I0eOoP7RFQgMHIjB13IyH2WHr5oc0rb9XUAIlJw9xu2mEFE33Jrcp4fDqFvxCGQ0iqE3/QC+Pt1tvUWUHoM/h7RufxdFnz8V/rIyt5tCRN0Qfj8ghKPL+aSUOPjbVdA++RiD538b6uDMdy0lOhGDP0dEjyZ262M3P1FOE0JAqEFHd+47+spmtLy5FZWXzUHpWG7sRb3D4M8R5m593KaXKOcpqurYrP72f+7G4f+3BiXjzkHF9JmO/JtU2Bj8OaJ1x7vwV1Rytz6iPKAEg47M6o80HkHdoyugDh6M6vnXcTIfWYKvohygh7lbH1E+EarqyOS+1tpa6K2tqL7+u1CKOJmPrMHgzwHt/9zF3fqI8ohQVUfG+HUtBABQBw+2/d8i72Dw54C27dshgkXcrY8oTzg1xq9rGoTfD+Hz2f5vkXcw+F1m7tZ35plQAgG3m0NEGRCqM2P8MqyZOwUSWYXB7zLu1keUf5SgM2P8uhaGEuT23WQtBr/LzN36zuJufUT5wqnJfaz4yQ4Mfpdxtz6i/KOoqiM79+maZl4bgMgqDH4XRY82cbc+ojwk1KAzXf3hMESQFT9Zi8HvolZjtz4GP1FeiVf8YUgpbf13ZJgVP1mPwe+itu3vwl9ZCXUod+sjyidCVQFdB2IxW/8dXWPFT9Zj8LtED4fRvnsXSrlbH1HeMapwu8f54xU/g5+sxeB3ibFbX8kYXmmLKN8YM+3tHufXNY3L+chyDH6XtG1/N75b34iRbjeFiHrIrPht3rZXhsNczkeWY/C7wNytb/Ro7tZHlIdEIvjtrPillFzOR7Zg8LtA++RjRJuaUHI2N+0hykdG97udY/wyGgGk5OQ+shyD3wXcrY8ovzkxxi8Twwis+MlqDH4XtG5/F0WnDudufUR5KjnGb1/Fb/QmsOInqzH4HRY92gTt473ctIcojzlS8YdZ8ZM9GPwOM3br4za9RPkrOcZvX/AbvQkKK36yGIPfYW3b34V/wACoQ4a63RQiylJyVr+Nk/sSHyq4nI+sxuB3kLlb39ncrY8onxm76TlS8TP4yWIMfge17zZ262M3P1E+E4n9N+wc4zeCX3DnPrIYg99B3K2PqDAIRYEIBGyt+JOT+1jxk7UY/A6RUqJ1x7vcrY+oQAhVtXWMn8v5yC4MfodoH3+M2NGjKDmb3fxEhUBRg/ZW/NzAh2zC4HdI247Ebn1nn+12U4jIAvGK38Yx/jCX85E9GPwOMXfr68vd+ogKgaKq9o/x+3wQfr9t/wZ5E4PfAVLXoX3yMYpHnuF2U4jIIkJVze54O/DKfGQXBr8DZCR+lS2lT7HbTSEii8TH+O2d3MfNe8gODH4HmBtxFPFNTFQoRNDeMX6phVnxky0Y/A7QtRAAbr1JVEjsHuPXwxqX8pEtGPwOkKz4iQqO3bP6WfGTXRj8DuBVtogKT7zit3eMn+cMsgOD3wHJ4C9yuSVEZBWhBs3ePDtIdvWTTRj8DpDGGD/fxEQFQ1FVyGgUUtdteX6dXf1kEwa/A9jVT1R4RCKU7Rrn53I+sguD3wHs6icqPMYHebtm9ktu4EM2YfA7QGq8yhZRoUlW/PaM8+vhMM8ZZAsGvwPY1U9UeBTVvopfRqNALMaKn2zB4HeArmkQgQCEwsNNVCjsHOPnlfnITkwiB+haiOP7RAXGqMZtqfgTz8mufrIDg98BUtMgguyyIyokdo7xm8OD7OonGzD4HaBrGit+ogJjjvHbcGles+Lncj6yAYPfAfHg5xuYqJDYOsZvTghmxU/WY/A7IN7Vz+AnKiRGKNsxxm8EPyt+sgOD3wGs+IkKj51j/EYvgsLgJxsw+B3AWf1EhcfOdfzJ5Xzs6ifrMfgdoHNWP1Hh8fkARbFljF9qXM5H9mHwO0ByVj9RwRFCQFFVeyt+dvWTDRj8NpNSQg+FOMZPVICEqto6xs+eQrIDg99mMhoBpGTwExUgRQ3aN6tfCAh/wPLnJmLw20yGeGU+okIlVNW8+qaV9HAYQg1CCGH5cxPlRPC/8MILmDlzJr7whS/gd7/7Xcp9x48fxw9/+ENMnjwZU6ZMwZYtW1xqZXaSs3M5xk9UaIRNY/xS07hdL9nG73YDAGDUqFF4+OGH8dhjj3W671e/+hVKS0uxefNm7N27F9/85jexadMmlJSUuNDSntNDvMoWUaFSVNW2nft4ziC75ETFP2LECJx22mlQurhs7YYNG/D1r38dADBs2DCMHj0ar7/+utNNzJq5AxffxEQFR9g0xi/DYZ4zyDY5Efzp1NXVYejQoeb31dXVOHDggIst6hmphQCw4icqRErQnln9ephd/WQfR7r658yZg7q6ui7v27p1K3w+n+1tqKwstfT5qqr6ZvS4xj3xz1aVgytQmuHP5KNMj4dX8HgkFfKxaCorRWRftEe/YyaPPSBjEKXFBX3sgMJ+bWTDqePhSPA///zzWf/skCFDsH//flRUVAAA6uvrcf755/f4eY4caYWuy6zb0VFVVV8cPtyS0WObDx0FABxrj+J4hj+Tb3pyPLyAxyOp0I9FWBeIHg9l/Dtmejy01nb4+/cv6GNX6K+NnrLyeCiKSFvs5nxX/5QpU/D0008DAPbu3YudO3diwoQJLrcqc9Ic4+esfqJCY+fOfbwyH9klJ4J/3bp1mDhxIjZu3Iif/exnmDhxIj788EMAwPz589Hc3IzJkyfj+uuvx7333ovSUmu77e2kc4yfqGCJxBi/lNb0JhqkFuYYP9kmJ5bzzZgxAzNmzOjyvuLiYjzyyCMOt8g6xqx+Bj9R4VHUICAlZDQKEbBul734hb14ziB75ETFX8h0TQN8Pgh/TnzGIiILiURVbvVafslZ/WQjBr/NeGU+osJlBL+V4/xS1yGjUfYSkm0Y/DbjDlxEhUsxK37r1vIbz8WufrILg99mDH6iwmXMvLeyq9+cF8SufrIJg99mUgvxkztRgVJs6Oo3novL+cguDH6bseInKlx2TO6T5kogVvxkDwa/zRj8RIVLSVTlRve8FcwLe7HiJ5sw+G0mNY279hEVKFsq/sRzcYyf7MLgtxkrfqLCZXTH6xbO6uemX2Q3Br/NGPxEhcuWdfzG5D6eN8gmDH6b6ZzVT1SwjDF+qVk5q5/L+cheDH4byWgUiMVY8RMVKGN/fku7+lnxk80Y/DYyx+qKOLmPqBAJRYFQVXuW83FWP9mEwW8jnW9gooInVNWeDXwsvNofUUcMfhtJLQQAEEUMfqJCpdhQ8QtVhVB4eiZ78JVlI10z1uMy+IkKVbyr39rlfDxnkJ0Y/DbSExU/x/iJCpeiBi1fzie4XS/ZiMFvI269SVT4rJ7cp4dZ8ZO9GPw2MmfncoyfqGApVk/u08Jcyke2YvDbiFtvEhU+q8f4ZVjj5j1kKwa/jcwxfl6kh6hgWT3Gr4fDHB4kWzH4bWR09XOiDlHhsmMDH4XnDLIRg99GuqYBigLh50YcRIVKUVVz6a4VuJyP7Mbgt5FxZT4hhNtNISKbWD/Gz8l9ZC8Gv414ZT6iwqcEg5DRKKSuW/J8Oif3kc0Y/DaSiYqfiAqXSIS0FeP8UtdZ8ZPtGPw2inf1c0Y/USEzqnNj+W5vyEgk5TmJ7MDgt5HOip+o4FlZ8ethYyUQzxtkHwa/jaSm8Q1MVOCMGfhWrOU3d/tkxU82YvDbSNdCrPiJClyy4u99Vz+v6ElOYPDbiF39RIXPHOO3ouJnVz85gMFvI51d/UQFz3iPWzLGz65+cgCD30aSs/qJCl6y4regqz/x4YEFA9mJwW8TqeuQkQi7+okKnHFBHUvW8YdZ8ZP9GPw24SV5ibzByjF+Y3IfK36yE4PfJjJxSV6+gYkKmzmr34IL9bDiJycw+G3Cip/IG+wY4+d5g+zE4LcJg5/IG4TfD/h81ozxJ84bguv4yUYMfpuYb2DO6icqeIqqWjTGr0H4/RAKT81kH766bKInxvhZ8RMVPqGqFu3Vzyvzkf0Y/DZhVz+Rd8Qrfguuzqdp3K6XbMfgt4ke4tabRF4h1KCFFT9n9JO9GPw2MZflcIyfqOBZNcYvw6z4yX4MfpsYFT+7+okKn5Vj/DxnkN0Y/DbRwxogBEQg4HZTiMhmiqqa83p6Q2qauSEQkV0Y/DaRoRCEqnJZDpEHWFbxc3IfOYCpZBM9rLHLjsgjFDVozax+Tu4jBzD4baKHeEleIq9gxU/5hMFvEz2scSkfkUdYtnMfN/AhBzD4bSJD7Oon8goRjFf8Usqsn0NKmVjOx65+sheD3yYc4yfyDkUNAlJCRiNZP4eMRgAped4g2zH4baKHQhzjJ/II42p6Usu+u9/4WS7nI7sx+G0iwxpn5xJ5hNE935txfmNVACf3kd0Y/DbhrH4i7zA+5PdmZn/yUt4MfrIXg98mHOMn8o5kxZ/9Wn490dXPyX1kNwa/DaSux7feZPATeYI5xm9BVz/PG2Q3Br8NZCQ+s5cVP5E3WDHGb17RkxU/2YzBbwM9FALAS/ISeYUxE79XFb/R1c+CgWzG4LeBOTuXb2AiT7BijN+o+Lmcj+zG4LeBDHGsjshLrBnjZ8VPzmDw20DXjK5+voGJvMCSMX5jOR/X8ZPNGPw20DWjq59j/EReYI7x92LnPvO8wa5+spnf7QYAwH/913/hzTffhKqqKC4uxh133IGzzjoLANDQ0IBbbrkF+/fvRzAYxJIlSzBmzBiXW5yebm7EwTcwkReIQABAL9fxh8OAzwfhz4nTMhWwnKj4J06ciD/84Q948cUXcf311+Pmm28271u2bBlqamrw8ssv46677sKiRYt6dQUsJ0hW/ESeIhQFQlXNCXrZkBqvzEfOyIngv/jiixFIfGIeO3YsDhw4AF3XAQAbN27E3LlzAQA1NTVQVRU7d+50ra2Z4Bg/kfcIVe3lXv1hTggmR+RE8He0evVqXHTRRVAUBU1NTZBSoqKiwry/uroaBw4ccLGFJ2eO1RXxTUzkFYqq9u7qfGGNF+ghRzgymDRnzhzU1dV1ed/WrVvh8/kAAC+99BL+8Ic/YPXq1Za3obKy1NLnq6rq2+19xxNHdeCQSojE71bo0h0PL+LxSPLKsdjXpwgBoZ/09+3u/gbo0Ev6eOZ4Ad55bWTKqePhSPA///zzJ33M5s2b8fDDD2PVqlUYMGAAAKC8vBwA0NjYaFb99fX1GDx4cI/bcORIK3TdmrkBVVV9cfhwS7f3tzY2Q6gqGhrbLfn3ct3JjofX8HgkeelY6L4AQi1taX/fdMcj1NIGXfF75nh56bWRCSuPh6KItMVuTnT1b9myBffffz9+9atf4TOf+UzKfVOmTMGaNWsAALW1tQiFQhg9erQbzcyYrrHLjshrlGCwd2P8PG+QQ3Ji3chtt92GQCCA73//++Ztq1atQnl5ORYsWIBFixZh7dq1CAaDePDBB6EoOfF5pVtS0yA4vk/kKUJVoR8/nvXP6+EwfGVlFraIqGs5EfxvvfVWt/dVVVVh1apVzjXGAroW4id3Io8Rqgr92LGsf16y4ieH5HbpnKd0TeOMfiKPUVS113v1c9MvcgKD3wa6pnG/bSKPia/j793V+VjxkxMY/DaQmgaliLv2EXmJogZ7XfFz0y9yAoPfBpydS+Q9ohdd/TIaBWIx82I/RHZi8NuAY/xE3qOoKmQ0ChmL9fhnjSECFgzkBAa/DaQW4hg/kceYl+aN9Lzq1xNb/XKvfnICg99iUkpW/EQeZFTrehb79ZtX9GRXPzmAwW8xGYkAUrLLjshjzIo/i3F+o6ufFT85gcFvMeOTu+CsfiJPURJr8LPZtte4qh8rfnJCxjv3ffTRR9i4cSMaGhpw991346OPPkIkEsEZZ5xhZ/vyjq6FAHCSDpHXGBW/cVnunjAn97HiJwdkVPFv2LAB8+bNw8GDB/HCCy8AANrb2/HAAw/Y2rh8ZIzvcYyfyFuMD/syi018jJ/hcj5yQkYV/yOPPIKVK1fijDPOwIYNGwAAZ5xxBv75z3/a2rh8ZFT8nNVP5C1mxZ/VGH+iYGDFTw7IqOJvbGzEyJEjAQBCCPNv42tKMmfncoyfyFOU3kzuM+YGsWAgB2QU/GeeeabZxW946aWXcPbZZ9vSqHxmvIH5yZ3IW4TZ1c/lfJTbMurqv+OOOzB//nw888wzaG9vx/z587Fnzx488cQTdrcv7zD4ibxJMbv6s5ncxw18yDkZBf/w4cOxYcMGbNmyBRdddBGqq6tx0UUXoaSkxO725R1zjD/Irn4iL+nNOn6paYAQEP6MF1oRZS3jV1mfPn0wbdo0O9tSEMwuO15Xm8hTlF5O7lOCQQTjtWcAACAASURBVM6bIkdkFPzf+MY3un1Brl692tIG5Tuzq5+TdIg8Rfj9gM+XXcUf1riUjxyTUfBffvnlKd8fPnwYzz77LGbOnGlLo/KZrmkQfj+77Ig8SFHV7Mb4tTDnBZFjMkqnOXPmdLrt0ksvxW233YabbrrJ8kblM6mFOEGHyKOEGsx6r34u5SOnZL1X/6BBg/D+++9b2ZaCwE/uRN6lqGrWV+fjvCBySkYV/zPPPJPyfSgUwqZNmzB27FhbGpXPdC0EhTP6iTxJqGqWFX+YFT85JqPgP3HznuLiYowbNw5XXXWVHW3Ka1LT2NVP5FFKMLsxfqlp8BUX29Aios4yCv7f/va3drejYOiaxq5+Io/KfoyfQ4TknG6Df9++fRk9wWc/+1nLGlMIdE2Dv18/t5tBRC5QVBXRY8d6/HOSk/vIQd0G/+TJkyGEgJSy2x8WQmD37t22NCxfxcf4B7rdDCJyQdZj/FqYk/vIMd0GPy+5mx2O8RN5V7br+Fnxk5OyXs5HXYuP8XNWP5EXCTUI2cPlfDIWg4xGOcZPjslocl80GsWTTz6Jv/71r2hqakrp/ueWvak4uY/Iu7Kp+M0r83HLXnJIRhX//fffj6effho1NTV477338O///u84cuQI/u3f/s3u9uUVGY0CsRi7+ok8yhjjTzc36kSS1/cgh2UU/Js2bcIvf/lLfOtb34LP58O3vvUtrFixAtu2bbO7fXlFD8UvycuKn8ibjCv0yUgk458xKn6eN8gpGQV/KBRCdXU1AKCoqAjHjx/H8OHDsWvXLlsbl2+MLj6+gYm8yZig15OZ/UbFz65+ckraMX5d16EoCoYPH46dO3fi7LPPxujRo7F8+XKUlpZi0KBBTrUzL+ihxBuYwU/kSUbFr4c1+FCa0c+wYCCnpQ3+iRMnYtasWVi4cCH8icvMLl68GPfccw/a2tqwZMkSRxqZL6T5BuasfiIvEom1+D2q+I3JfQx+ckja4L/nnnvw4osv4pprrsHw4cMxe/ZszJw5E6tWrXKoefmFY/xE3pas+DMPft2c3MeufnJG2uCfNGkSJk2ahObmZqxfvx4vvPACHnroIYwfPx5f/epXcfHFFyMQCDjV1pzHLjsibzPH+Huwlt84b3ADH3JKRpP7ysrKMHfuXDz11FPYsGEDRo8ejfvuuw/jx4+3u315RXKMn8jTjCV5PVnLby7n45a95JAe7dwXDoexc+dO7NixAw0NDRgxYoRd7cpLOsf4iTwtmzF+czkfK35ySEY799XW1uKFF17Axo0bUVFRgVmzZuHuu+/G0KFD7W5fXjFm9bOrn8ibshnj53I+clra4F++fDlefPFFHD16FFOmTMGjjz6Kc88916m25R1jVj+7+om8yQhv2YOufj0cBoRg8JNj0gb/9u3b8cMf/hCTJk1CkGF2UnooBCgKhD+jjhQiKjDJMf6eVfxCVSGEsKtZRCnSJtTjjz/uVDsKgh6OX6CHb2Aib0pW/D0b4+dSPnISL8trIT2ksZufyMNEYnlzj9bxh3neIGcx+C0kwxpn9BN5mEiM1fdkjF9qGit+chSD30J6KMQZ/UQep6jBHlb8YW7eQ45i8FtID4cZ/EQeJ1TVXKKXCVb85DQGv4X0UIhjdUQep6hqjyt+FgzkJAa/hWRiVj8ReVd8jL+Hy/l43iAHMfgtpIc4uY/I65Rgz8f42dVPTmLwW4jLcoiop7P6ed4gpzH4LSQ5q5/I84SqQu/BZXklK35yGIPfIjIWg4xGGfxEHqf0YIxf6jokl/ORwxj8FtE1XpKXiBIVf6bBz0vykgsY/BbhlfmICIhP7st0jN/4gKAE2dVPzmHwW0QPJSr+IgY/kZf1ZOc+Y6MfdvWTkxj8FtETn/DZZUfkbUJVgcScn5NJVvw8b5BzGPwW0UMhAIBSxDF+Ii8zZujrkchJH2vMDRLs6icHMfgtYo7xc1kOkacZ54BMxvklewrJBQx+iyTH+FnxE3mZEeKZjPPrYY7xk/MY/BYxl/PxDUzkacmK/+TBLzXO6ifnMfgtIrX4GL/grH4iTzOCP5Pd+zgpmNzA4LeI8SbnG5jI25SejPFrnBtEzvO73QAA+MUvfoH169fD5/NBSonrr78e06ZNAwAcP34ct912G9577z34fD7ceuutuPjii11ucWe6FgKE4BuYyONEj8b4uZyPnJcTwT9v3jx85zvfAQAcPHgQU6dOxQUXXIB+/frhV7/6FUpLS7F582bs3bsX3/zmN7Fp0yaUlJS43OpUuqZBqEEIIdxuChG5yBivz6Ti11nxkwtyoqu/b9++5tft7e0QQkDXdQDAhg0b8PWvfx0AMGzYMIwePRqvv/66K+1MR2oad+0joh6N8ctwGCIQgFBy4lRMHpETFT8APPXUU/j1r3+NAwcO4L777kN5eTkAoK6uDkOHDjUfV11djQMHDrjVzG7pWojj+0TUYYw/s8l9vL4HOc2R4J8zZw7q6uq6vG/r1q3w+Xy44oorcMUVV+D999/HwoUL8aUvfckMfytUVpZa9lwAUFXVN+X7BsSglxZ3ut0rvPp7d4fHI8lrxyJa4sP/B6BYFV3+7h1vOyokjhcVee4YGbz6e3fHqePhSPA///zzGT925MiRGDhwIN5++21ceumlGDJkCPbv34+KigoAQH19Pc4///wet+HIkVbouuzxz3WlqqovDh9uSbkt1NwGXfF3ut0LujoeXsbjkeTFY2Hs0d/S2Nzpdz/xeLQ3twL+gOeOEeDN10Y6Vh4PRRFpi92cGFj68MMPza/37duH3bt347TTTgMATJkyBU8//TQAYO/evdi5cycmTJjgSjvT0TWNu/YREYTfD/h8Gc3ql5rGiX3kuJwY41++fDk+/PBD+P1++Hw+/PjHP8bw4cMBAPPnz8fixYsxefJkKIqCe++9F6Wl1nbbW0HXNPj79Xe7GUSUAxRVzXCMP8ylfOS4nAj+n/3sZ93eV1xcjEceecTB1mRHahp37SMiAPG1/HqGy/l8OVjIUGHLia7+QsBZ/URkyLTil+GwuQqAyCkMfovoXMdPRAkiGMz46nxczkdOY/BbQOp6fCMOVvxEhB5U/BorfnIeg98Cxhucs/qJCIjv3pfpBj4cIiSnMfgtoCcuycs3MBEB8Yrf2Ie/O1LKeE9hkBU/OYvBbwHzkrwc4ycixGf1n6zil5EIICULBnIcg98CMlHxc4yfiIBExX+y4DeuzMfJfeQwBr8FjC49jvETEQCI4MnH+I0PBpzcR05j8FvADH5W/EQEo+JPP8avs+InlzD4LZCs+PkGJqLkGL+U3V8YzFwNxIKBHMbgtwDH+ImoI6P7Pl13v9EjwL36yWkMfguw4ieijkQGwW9O7uMYPzmMwW8BM/j5yZ2IkKz4083sNyt+9hSSwxj8Fkh+cucbmIiS5wKZZoKfTOz/wcl95DQGvwV0LQShqhAKDycR9bTiZ1c/OYtJZQFdC7Obn4hMmYzxczkfuYXBbwFdC0EJcvMeIoozxu3TVfySG/iQSxj8FpAar6lNREnGhXfSjfHrmgbh90P4fE41iwgAg98Suqaxq5+ITJmM8ctwmEv5yBUMfgsw+ImoI3OMX0s/uY/nDXIDg98CUguxq5+ITBmN8WsaK35yBYPfApzVT0QdZTTGHw5z8x5yBYPfApzVT0QdCX8AECL9On5OCiaXMPgtwFn9RNSREAJCVdPv1R8OcykfuYLB30tSSk7uI6JOFFVlxU85icHfSzISAaRk8BNRinjFn2avflb85BIGfy/pWggAr8xHRKkUNXjSvfp53iA3MPh7SYa43zYRdXbSMX4u5yOXMPh7ybzCFmf1E1EHiqqaF+I5kZSSy/nINQz+XtJD7Oonos7SVfwyGgV0nT2F5AoGfy8Zb2y+gYmoo3Rj/LwyH7mJwd9LrPiJqCvpZvUbQwAsGMgNDP5e4hg/EXVFCXa/jp8VP7mJwd9LOmf1E1EX0o3xJwsGnjfIeQz+XpIa38BE1FnaMX6jq5+z+skFDP5e4gY+RNQVoapALBafwX8C3ezq53mDnMfg7yVd0yD8fgifz+2mEFEOMcbvu6r6k5P7OMZPzmPw9xIvtEFEXTF25etqnN+Y7c+Kn9zA4O8lqWmc0U9EnRjDf11X/Nz/g9zD4O8lXQtxfJ+IOklW/J3X8icrfnb1k/MY/L2ka2F+aieiToxu/HRj/CwayA0M/l6SrPiJqAvpx/jDgKIAnBRMLmDw95Ku8ZraRNRZclZ/565+PRw/bwghnG4WEYO/txj8RNQVY3Oerip+XdO4eQ+5hsHfSzKsQXBWPxGdwKz4ta67+jmxj9zC4O8lPcQxfiLqLN0YP/f/IDcx+HtBSgk9HGbwE1EnSrD7MX5W/OQmBn8vyGgUiMX4yZ2IOhGB9BU/CwZyC4O/F5JX5uMYPxGlEj4fhN9vrtnvSIbD5lAAkdMY/L1gbsJRxE/uRNSZUNWuK/4wK35yD4O/F8zg57IcIuqCUNVud+7jcj5yC4O/F6QWAgAIVvxE1AVFDXa7cx8n95FbGPy9wIqfiNKJV/xd7NzH5XzkIgZ/LyTH+Dm5j4g6U7oY4zdWA7HiJ7cw+HvBmNXPsToi6kpXY/zG95zcR25h8PeCnhjj56x+IupKlxV/4nsu5yO3MPh7wdiDm2P8RNQVoQY7jfGbQ4Ss+MklDP5eSFb8HOMnos6UYOdZ/TLMIUJyF4O/F6SmAYnduYiITpR+jJ9d/eQOBn8vcL9tIkqnqzF+nZOCyWUM/l5g8BNROsaWvVLXzduMDwKcG0RuYfD3gtRC3ISDiLplhLuMRMzbkpP72NVP7sip4N+2bRtGjRqF3/3ud+ZtDQ0NuOaaa3DppZdi1qxZ2L59u4stTKVrGj+1E1G3RLDzpXk5uY/cljPB39raip/+9KeYOHFiyu3Lli1DTU0NXn75Zdx1111YtGgRpJQutTKVrmmc0U9E3TJ25+s4wc9cBszeQnJJzgT/Aw88gPnz56O8vDzl9o0bN2Lu3LkAgJqaGqiqip07d7rRxE54hS0iSsfYpMfo3gc6Vvzs6id35ETwv/baa2hpacGUKVNSbm9qaoKUEhUVFeZt1dXVOHDggNNN7JLUNO7aR0TdMsf4O1b8YQ0QAiIQcKtZ5HGOLECfM2cO6urqurxv48aNWLZsGVauXGlrGyorSy19vqqqvtgbCaO4rBRVVX0tfe58xGOQiscjycvHIlDVD3UAyop96Jc4DkWKhBIMYuDAMncblwO8/NroilPHw5Hgf/7557u9r7a2FocPH8bll18OIF7lb9myBUePHsVNN90EAGhsbDSr/vr6egwePLjHbThypBW6bs3cgKqqvjh8uAXR48cRhoLDh1ssed58ZRwPiuPxSPL6sTh+PAYAaDp0FOGBLaiq6ou2Y60QAdXTxwXga+NEVh4PRRFpi13Xt5yrqanBm2++aX6/ePFijB49GvPmzQMATJkyBWvWrMGNN96I2tpahEIhjB492q3mppAc4yeiNESXk/u4/we5y/XgP5kFCxZg0aJFWLt2LYLBIB588EEoivtTE2Q0ChmNclY/EXUrOcbfcXJfmBP7yFU5F/wPPPBAyvdVVVVYtWqVO41Jw7jiFtfxE1F3WPFTLnK/dM5TxlpcwVn9RNQNYx1/6gY+rPjJXQz+LEnjkrz85E5E3ehq5z5W/OQ2Bn+Wkvttc4yfiLom/AFACHNoEIgPE3JSMLmJwZ+lZPDzDUxEXRNCxK/Qp6V29Svs6icXMfizJI1rajP4iSgNRQ12mtzH8wa5icGfJZ1j/ESUARFUO03uY8VPbmLwZ4ld/USUCUVVzTF+GYtBRiI8b5CrGPxZ0tnVT0QZEGrQrPiNLn8u5yM3MfizJDmrn4gyEK/444EfY08h5QAGf5Z0LcRLaxLRSQk1Ocavh0KJ2xj85B4Gf5Z0LQwlGIQQwu2mEFEOS634438rQXb1k3sY/FmSWojj+0R0UvF1/PEuflb8lAsY/FmKb7vJ8X0iSi++jj8e/OYYPyf3kYsY/FmKBz/fvESUXsoYPyf3UQ5g8GdJahoEK34iOgljjF9KmVwGzK5+chGDP0u6FuKndiI6KaGqgK4DsRhiIaPiZ28huYfBnyVjVj8RUTpKorrXwxo3/qKcwODPUrziZ1c/EaUnEtW9DIc7TO5j8JN7GPxZkrzCFhFlwJjBr2vh5HI+bvxFLmLwZyk+q5/BT0TpGfvyGxW/UFUIhadecg9ffVmQsVj80poMfiI6iRPH+NnNT25j8GfB2HaTXf1EdDIdK349UfETuYnBnwVdi4/TseInopMxx/jDYcRCHCIk9zH4sxALGcHPWf1ElJ7RM2hW/Ax+chmDPwt6iGtxiSgzyYpfQ0zTuE8/uY7Bn4Vkxc/gJ6L0jO15ZTi+nI/b9ZLbGPxZYPATUaZSxvh5cS/KAQz+LOgc4yeiDJ04q5/L+chtDP4sxI4ndt9ixU9EJyEUBcLvh65pXM5HOYHBn4UYl/MRUQ8INQgZ1ricj3KC3+0G5COj4ucbmIgyoQTV+F79rPgtI6VEa+sxHD/eCl2Pud2cXjt0SIGu6z3+Ob9fRXl5FXy+zOOcwZ8F89KafAMTUQaEqiLW1gqABYNVmpoOQwiBiopB8Pn8EEK43aRe8fsVRKM9C34pJdramtHUdBgDBlRn/HPs6s9CLBTihTaIKGOKqiLW0gKAc4OsEg6H0L9/Jfz+QN6HfraEECgpKUM0Gu7RzzG5sqCHQpzRT0QZE2oQsdZ48HMDH6tICMEIy+ZDD49aFmKhELvriChjHSt+LucjtzH4sxALcb9tIsqcUFXo7e3m11R4Fiz4PtaufSblNiklLr/8Mrzzzt96/HxXXfUNaIkVZFZj8GdBZ8VPRD3QsXuf547CNH36LKxfvy7ltnfe+RsURWDs2HN6/HyrVj2JoE1DypzVn4UYx/iJqAc67s/Pit8ezVv/gmN/ft2W5+43fiLKvnxB2sdMmHAhli27H3v37sGwYZ8HALz00ouYNm1mt+Pw48fX4Oqrr8Mbb7yGcFjDt799Iy666CvmfZs2vY7i4mJrfxmw4s9KLBSC4H7bRJQhwYq/4AUCAUyePBXr178IAGhvb8Mbb7yGqVNnpP05RVGwatWTeOihh/Hgg/ehqanR9ray4s+CHtIQYMVPRBnq2NXP+UH2KPvyBSetyu02ffosLFz4PVx//U145ZXNOOusMRg4cFDan5kx4zIAwCmnDMOIESPx3ns7MX78hba2kxV/Fjirn4h6IqXiZ1d/wTr99BGorKzCW29txfr1L2L69FluN6lLDP4sMPiJqCc6LuHjuaOwTZ8+C0888Rj27fsEEyacvHJ/6aX40MAnn3yCDz54H2eeeZbdTWRXf09JKeP7bfPNS0QZUjrMCRJcx1/QJk+eghUrfoZZs+YgEAic9PGxWAxXX/0NaJqGRYtuR3l5he1tZPD3kAyHASk5q5+IMmaEvQgEuNV3gSsrK8Of/vSXjB9/xRVXYv786zvt1f/nP9fa0TwA7OrvMeMCPQpn9RNRhoxxfR97CikHsOLvIWlcmY8VPxFlyJjcx/F971m58pd47bUtnW5/+OH/s7WqT4fB30N6YgtFvoGJKFPG+cJXxPOG11x99XW4+urr3G5GCnb195DZ1c83MBFliBU/5RIGfw8Zwc+ZuUSUKXOMv4hDhOQ+Bn8PSbPi5xuYiDJjVvzcvIdyAIO/hzjGT0Q9ZfQQsmCgXMDg7yFdCwNg8BNR5ricj3IJg7+HZKLi53I+IsqU2dXPScEFa8GC72Pt2mdSbpNS4vLLL8M77/zNpVZ1jcHfQ8kNfPgGJqLMCL8fEIIVfwGbPn0W1q9fl3LbO+/8DYoiMHbsOS61qmtcx99DxWeehSI/uO0mEWVMCIGKaTNQ+aXzobndmAL1l531+POOeluee/zZ1bjgrOq0j5kw4UIsW3Y/9u7dg2HDPg8gfgGeadNmQgjR6fH19XW49tor8dJLrwAA6urqcPXV38RLL71i3jdlygzU1m6DlBILFizGmDHjLPl9mF491OfUUzHsP+e53QwiyjMD5nwNZV8Y5XYzyCaBQACTJ0/F+vXxq+21t7fhjTdew9SpM7J6vmPHjuG0007Hr3+9Bj/84SLcc88dCIfDlrSVFT8REeW9C846eVVut+nTZ2Hhwu/h+utvwiuvbMZZZ43BwIGDsnquQCCASy+dBgA455waBINBfPLJxzjttNN73U5W/ERERBY4/fQRqKyswltvbcX69S9i+vRZ3T7W5/NB16X5fTjs3CAQg5+IiMgi06fPwhNPPIZ9+z7BhAkXdvu4iopKRKNRfPrpPgDApk0bU+6PRCLYvDl+2/bt70DTNJxyyjBL2siufiIiIotMnjwFK1b8DLNmzUEgEOj2cX6/Hz/4wQLcfPN30b9/f1xwwYSU+/v164cPPvgXnnzyN5BS4p57fpL2+XqCwU9ERGSRsrIy/OlPf8nosTNmXIYZMy4DAPj9Cq66KvUqfjfd9EPL2wewq5+IiMhTcqLiX7x4MbZu3Yry8nIAwJQpU/Cd73wHANDQ0IBbbrkF+/fvRzAYxJIlSzBmzBg3m0tERJSRlSt/idde29Lp9ocf/j+Ul1d0+TPV1UPM9f12yIngB4Bvf/vbmDev8/r4ZcuWoaamBk888QRqa2uxaNEivPzyy11uiEBERJRLrr76Olx99XUnf6CDcr6rf+PGjZg7dy4AoKamBqqqYufOnS63ioiI3CUgpe52I1wnpTz5g06QM8G/cuVKzJw5EzfeeCM++ugjAEBTUxOklKioSHaHVFdX48CBA241k4iIcoCqFuHo0QZEo5Gswq8QSCnR1tYMv1/t0c850tU/Z84c1NXVdXnf1q1bcfPNN6OqqgqKomDt2rW49tpr8cc//tHSNlRWllr6fFVVfS19vnzH45GKxyOJxyIVj0dSb45FZWUJGhoa0NR0GNFozMJW5Zc+fYpw2mmf79FSP0eC//nnn097/6BByS0NZ8+ejfvvvx8HDhzA0KFDAQCNjY1m1V9fX4/Bgwf3uA1HjrSm7JLUG1VVfXH4cIslz1UIeDxS8Xgk8Vik4vFIsuJYCNEHFRV9LGqRu3pzPI4eDQEImd8rikhb7OZEV//BgwfNr9944w0oimJ+GJgyZQrWrFkDAKitrUUoFMLo0aNdaScREVG+y4lZ/bfeeiuOHDkCIQRKS0vxi1/8An5/vGkLFizAokWLsHbtWgSDQTz44INQeElcIiKirORE8K9atarb+6qqqtLenylFsXb5n9XPl+94PFLxeCTxWKTi8UjisUhl1fE42fMI6dXpkERERB7EPnMiIiIPYfATERF5CIOfiIjIQxj8REREHsLgJyIi8hAGPxERkYcw+ImIiDyEwU9EROQhDH4iIiIPyYkte/PFnj17sHjxYhw9ehT9+/fH0qVLMWzYMLeb5ZpLLrkEqqoiGAwCABYuXIgJEya43CrnLF26FC+//DL279+PP/zhDxgxYgQAb75OujsWXn2NNDU14ZZbbsEnn3wCVVVxyimn4N5770VFRQXeffdd3HXXXdA0DUOHDsVDDz2EyspKt5tsm3THYuTIkRgxYoR5/ZUHH3wQI0eOdLnF9rvxxhvx6aefQlEUFBcX484778SoUaOcO3dIytiVV14p165dK6WUcu3atfLKK690uUXuuvjii+X777/vdjNc89e//lXW1dV1Og5efJ10dyy8+hppamqSb731lvn9Aw88IG+77TYZi8XkpEmT5F//+lcppZQrVqyQixcvdquZjujuWEgp5YgRI2Rra6tbTXNNc3Oz+fXmzZvl7NmzpZTOnTvY1Z+hI0eOYNeuXZgxYwYAYMaMGdi1axcaGxtdbhm5paamBtXV1Sm3efV10tWx8LL+/fvj/PPPN78fO3Ys6urq8I9//APBYBA1NTUAgLlz52Ljxo1uNdMR3R0LL+vbt6/5dWtrK4QQjp472NWfofr6egwaNAg+nw8A4PP5MHDgQNTX16OiosLl1rln4cKFkFLi3HPPxY9+9COUlZW53SRX8XXSmddfI7qu46mnnsIll1yC+vp6DBkyxLyvoqICuq6bXbuFruOxMFx55ZWIxWKYOHEivve970FVVRdb6Jw77rgDf/nLXyClxOOPP+7ouYMVP2Vt9erVePHFF/Hss89CSol7773X7SZRjuFrBFiyZAmKi4sxb948t5viuhOPxauvvornnnsOq1evxocffogVK1a43ELn/OQnP8Grr76Km2++GQ8++KCj/zaDP0PV1dU4ePAgYrEYACAWi+HQoUOe7t40fndVVfGNb3wDf//7311ukfv4Oknl9dfI0qVL8fHHH+N///d/oSgKqqurU7q5GxsboSiKJ6r9E48FkHx9lJaW4vLLL/fc6wMAZs+ejW3btmHw4MGOnTsY/BmqrKzEqFGjsG7dOgDAunXrMGrUKM9237a3t6OlpQUAIKXE+vXrMWrUKJdb5T6+TpK8/hr5n//5H/zjH//AihUrzO7r0aNHIxQKoba2FgCwZs0aTJkyxc1mOqKrY3Hs2DGEQiEAQDQaxcsvv+yJ10dbWxvq6+vN7//0pz+hX79+jp47hJRSWv6sBeqjjz7C4sWL0dzcjLKyMixduhSnnnqq281yxb59+/C9730PsVgMuq5j+PDh+PGPf4yBAwe63TTH/Pd//zc2bdqEhoYGlJeXo3///njppZc8+Trp6lg8+uijnn2NfPDBB5gxYwaGDRuGoqIiAMBnPvMZrFixAn//+99x9913pyznGzBggMsttk93x+Laa6/FXXfdBSEEotEoxo0bh9tvvx0lJSUut9heDQ0NuPHGG3H8+HEoioJ+/frh1ltvxZlnnunYuYPBT0RE5CHs6iciIvIQBj8REZGHMPiJiIg8hMFPRETkIQx+IiIiD2HwExEReQiDn4hOqra2FnPnzsW5556L8847D3PnV7JwAAAAAzFJREFUzsWOHTvw3HPP4Yorrsj4eT799FOMHDkS0WjUxtYSUTq8SA8RpdXa2oobbrgB99xzD6ZOnYpIJILa2lrPXEyFqNCw4ieitPbs2QMgfplQn8+HoqIijB8/HoFAAHfffTfeffddjBs3zrzU7KuvvorZs2fjnHPOwYUXXojly5ebz2VcnOWLX/wixo0bh3feeQcA8Mwzz2Dq1Kn44he/iPnz52P//v0O/5ZE3sGd+4gordbWVnzlK1/BRRddhGnTpmHs2LHo168fAOC5557D73//ezz11FPm47dt24b+/fvj9NNPx7/+9S9cc801uPfeezFp0iR8+umn+MpXvoL33nsPfn+8w/GPf/wjli5dikcffRSnnHIKHnvsMbz++utYs2aNK78vUaFjxU9EaZWWluLJJ5+EEAJ33nknvvSlL+GGG25AQ0NDl48///zzMXLkSCiKgjPOOAPTp0/H22+/3e3zr1mzBt/+9rcxfPhw+P1+3HDDDdi9ezerfiKbcIyfiE5q+PDheOCBBwDEL1a1aNEi3HfffRg/fnynx27fvh0//elP8cEHHyASiSAcDqe9Al1dXR3uu+8+LF261LxNSomDBw9i6NCh1v8yRB7H4CeiHhk+fDi++tWv4umnn8aECRM63b9gwQLMmzcPjz/+OILBIH7yk5+gqakJACCE6PT46upq3HDDDZg1a5btbScidvUT0Ul89NFHeOKJJ3DgwAEAQH19PdatW4cxY8agsrISBw8eRDgcNh/f1taGfv36IRgMYseOHeb1xQGgoqICiqJg37595m1z587FY489hg8++AAA0NLSgg0bNjj02xF5Dyt+IkqrtLQU27dvx8qVK9HS0oK+ffvi4osvxi233AJVVXHaaadh/PjxEEJg27ZtuPvuu7F06VLce++9OO+88zB16lQ0NzcDAPr06YMbbrgBV1xxBaLRKB5//HFMnjwZbW1t+NGPfoT9+/ejb9+++PKXv4ypU6e6/JsTFSbO6iciIvIQdvUTERF5CIOfiIjIQxj8REREHsLgJyIi8hAGPxERkYcw+ImIiDyEwU9EROQhDH4iIiIPYfATERF5yP8PYGoOvC8o1woAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ZiZjHASGrv"
      },
      "source": [
        "plotBoundsRandomTraj_old(agent, environment, t, np.array(samples), V_pi, V_up, 3, gamma=0.99, filename=\"Pong-traj.png\")#not random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362,
          "referenced_widgets": [
            "9aca35c5cb6b4ab6b1584fb418886294",
            "ca50739231e2415abf1d8aa97a5e2f22",
            "bee5a4d363cc4d7dad46005cc797f84b",
            "043a22730f024d4fa6aa3d6cfa78e23f",
            "2d014d4d2b03498b814cd8545d91dda2",
            "07c14e5e14cb4f15955ef90b9b609a73",
            "4cc252a0bd524a1e90568a32371e6674",
            "179b44aedcd94ff688a3a3afd9252f18",
            "8b20445eddfa4a3c9802082708b0c703",
            "999521480e894c96b90fa1ed359189c9",
            "c0f425dae84b49199bbb82358f62edeb"
          ]
        },
        "id": "A1hirYbZBDqJ",
        "outputId": "67545eb1-b9fa-4d2b-fb08-aebf1941e3c5"
      },
      "source": [
        "plotBoundsRandomTraj_old(agent, environment, t, samples_rand, V_pi_rand, V_up_rand, 3, gamma=0.99, filename=\"Pong-traj.png\")#not random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aca35c5cb6b4ab6b1584fb418886294",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-21fec9c98bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_pi_rand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_traj_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mV_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetBounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c9fb60f15626>\u001b[0m in \u001b[0;36mget_traj_random\u001b[0;34m(n_samples, agent_, t)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstates_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#value_from_network(state, agent_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mvalues_at_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'td_value' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve4vYDe3bozg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bad3401-35d7-4ed2-d778-28611b4a9566"
      },
      "source": [
        "environment = Monitor(gym.make(ENVIRONMENT),'./video', force=True)  # Get env\n",
        "agent = Agent(environment, random_policy=True)  # Create Agent\n",
        "losses = []\n",
        "rewards = []\n",
        "LOAD_MODEL_FROM_FILE = False\n",
        "TRAIN_MODEL = True\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\", map_location=torch.device('cpu')))\n",
        "\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent.epsilon = param.get('epsilon')\n",
        "\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "\n",
        "else:\n",
        "    startEpisode = 1\n",
        "\n",
        "last_100_ep_reward = deque(maxlen=100)  # Last 100 episode rewards\n",
        "total_step = 1  # Cumulative sum of all steps in episodes\n",
        "for episode in range(startEpisode, MAX_EPISODE):\n",
        "\n",
        "    startTime = time.time()  # Keep time\n",
        "    state = environment.reset()  # Reset env\n",
        "\n",
        "    state = agent.preProcess(state)  # Process image\n",
        "\n",
        "    # Stack state . Every state contains 4 time contionusly frames\n",
        "    # We stack frames like 4 channel image\n",
        "    state = np.stack((state, state, state, state))\n",
        "\n",
        "    total_max_q_val = 0  # Total max q vals\n",
        "    total_reward = 0  # Total reward for each episode\n",
        "    total_loss = 0  # Total loss for each episode\n",
        "    for step in range(MAX_STEP):\n",
        "\n",
        "        if RENDER_GAME_WINDOW:\n",
        "            environment.render()  # Show state visually\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.act(state)  # Act\n",
        "        next_state, reward, done, info = environment.step(action)  # Observe\n",
        "\n",
        "        next_state = agent.preProcess(next_state)  # Process image\n",
        "\n",
        "        # Stack state . Every state contains 4 time contionusly frames\n",
        "        # We stack frames like 4 channel image\n",
        "        next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "\n",
        "        # Store the transition in memory\n",
        "        agent.storeResults(state, action, reward, next_state, done)  # Store to mem\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state  # Update state\n",
        "\n",
        "        if TRAIN_MODEL:\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            loss, max_q_val = agent.train()  # Train with random BATCH_SIZE state taken from mem\n",
        "        else:\n",
        "            loss, max_q_val = [0, 0]\n",
        "        losses.append(loss)\n",
        "        rewards.append(reward)\n",
        "        total_loss += loss\n",
        "        total_max_q_val += max_q_val\n",
        "        total_reward += reward\n",
        "        total_step += 1\n",
        "        if total_step % 1000 == 0:\n",
        "            agent.adaptiveEpsilon()  # Decrase epsilon\n",
        "\n",
        "        if done:  # Episode completed\n",
        "            currentTime = time.time()  # Keep current time\n",
        "            time_passed = currentTime - startTime  # Find episode duration\n",
        "            current_time_format = time.strftime(\"%H:%M:%S\", time.gmtime())  # Get current dateTime as HH:MM:SS\n",
        "            epsilonDict = {'epsilon': agent.epsilon}  # Create epsilon dict to save model as file\n",
        "\n",
        "            if SAVE_MODELS and episode % SAVE_MODEL_INTERVAL == 0:  # Save model as file\n",
        "                weightsPath = MODEL_PATH + str(episode) + '.pkl'\n",
        "                epsilonPath = MODEL_PATH + str(episode) + '.json'\n",
        "\n",
        "                torch.save(agent.online_model.state_dict(), weightsPath)\n",
        "                with open(epsilonPath, 'w') as outfile:\n",
        "                    json.dump(epsilonDict, outfile)\n",
        "\n",
        "            if TRAIN_MODEL:\n",
        "                agent.target_model.load_state_dict(agent.online_model.state_dict())  # Update target model\n",
        "\n",
        "            last_100_ep_reward.append(total_reward)\n",
        "            avg_max_q_val = total_max_q_val / step\n",
        "\n",
        "            outStr = \"Episode:{} Time:{} Reward:{:.2f} Loss:{:.2f} Last_100_Avg_Rew:{:.3f} Avg_Max_Q:{:.3f} Epsilon:{:.2f} Duration:{:.2f} Step:{} CStep:{}\".format(\n",
        "                episode, current_time_format, total_reward, total_loss, np.mean(last_100_ep_reward), avg_max_q_val, agent.epsilon, time_passed, step, total_step\n",
        "            )\n",
        "\n",
        "            print(outStr)\n",
        "\n",
        "            if SAVE_MODELS:\n",
        "                outputPath = MODEL_PATH + \"out\" + '.txt'  # Save outStr to file\n",
        "                with open(outputPath, 'a') as outfile:\n",
        "                    outfile.write(outStr+\"\\n\")\n",
        "\n",
        "            break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Time:16:01:23 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-21.000 Avg_Max_Q:0.000 Epsilon:1.00 Duration:2.62 Step:824 CStep:826\n",
            "Episode:2 Time:16:01:25 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.98 Duration:2.10 Step:960 CStep:1787\n",
            "Episode:3 Time:16:01:26 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.96 Duration:1.16 Step:1113 CStep:2901\n",
            "Episode:4 Time:16:01:27 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.94 Duration:0.93 Step:919 CStep:3821\n",
            "Episode:5 Time:16:01:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.92 Duration:0.86 Step:845 CStep:4667\n",
            "Episode:6 Time:16:01:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.90 Duration:0.97 Step:960 CStep:5628\n",
            "Episode:7 Time:16:01:30 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.429 Avg_Max_Q:0.000 Epsilon:0.89 Duration:0.97 Step:949 CStep:6578\n",
            "Episode:8 Time:16:01:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.87 Duration:0.82 Step:826 CStep:7405\n",
            "Episode:9 Time:16:01:32 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.444 Avg_Max_Q:0.000 Epsilon:0.85 Duration:1.86 Step:870 CStep:8276\n",
            "Episode:10 Time:16:01:33 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.95 Step:915 CStep:9192\n",
            "Episode:11 Time:16:01:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.455 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.78 Step:764 CStep:9957\n",
            "Episode:12 Time:16:01:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.82 Duration:0.84 Step:822 CStep:10780\n",
            "Episode:13 Time:16:01:36 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.538 Avg_Max_Q:0.000 Epsilon:0.80 Duration:0.95 Step:931 CStep:11712\n",
            "Episode:14 Time:16:01:37 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.357 Avg_Max_Q:0.000 Epsilon:0.78 Duration:1.04 Step:1027 CStep:12740\n",
            "Episode:15 Time:16:01:38 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.77 Duration:0.98 Step:948 CStep:13689\n",
            "Episode:16 Time:16:01:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.375 Avg_Max_Q:0.000 Epsilon:0.75 Duration:0.79 Step:764 CStep:14454\n",
            "Episode:17 Time:16:01:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.412 Avg_Max_Q:0.000 Epsilon:0.74 Duration:0.81 Step:792 CStep:15247\n",
            "Episode:18 Time:16:01:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.444 Avg_Max_Q:0.000 Epsilon:0.72 Duration:0.99 Step:968 CStep:16216\n",
            "Episode:19 Time:16:01:42 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.421 Avg_Max_Q:0.000 Epsilon:0.71 Duration:0.99 Step:966 CStep:17183\n",
            "Episode:20 Time:16:01:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.70 Duration:0.86 Step:840 CStep:18024\n",
            "Episode:21 Time:16:01:44 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.381 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.06 Step:1043 CStep:19068\n",
            "Episode:22 Time:16:01:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.409 Avg_Max_Q:0.000 Epsilon:0.68 Duration:0.78 Step:764 CStep:19833\n",
            "Episode:23 Time:16:01:45 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.304 Avg_Max_Q:0.000 Epsilon:0.67 Duration:1.03 Step:1012 CStep:20846\n",
            "Episode:24 Time:16:01:46 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.292 Avg_Max_Q:0.000 Epsilon:0.65 Duration:0.94 Step:916 CStep:21763\n",
            "Episode:25 Time:16:01:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.320 Avg_Max_Q:0.000 Epsilon:0.64 Duration:0.87 Step:852 CStep:22616\n",
            "Episode:26 Time:16:01:48 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.308 Avg_Max_Q:0.000 Epsilon:0.63 Duration:1.17 Step:1128 CStep:23745\n",
            "Episode:27 Time:16:01:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.62 Duration:0.84 Step:811 CStep:24557\n",
            "Episode:28 Time:16:01:51 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.321 Avg_Max_Q:0.000 Epsilon:0.60 Duration:2.26 Step:1009 CStep:25567\n",
            "Episode:29 Time:16:01:53 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.276 Avg_Max_Q:0.000 Epsilon:0.59 Duration:1.12 Step:1058 CStep:26626\n",
            "Episode:30 Time:16:01:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.58 Duration:1.02 Step:993 CStep:27620\n",
            "Episode:31 Time:16:01:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.323 Avg_Max_Q:0.000 Epsilon:0.57 Duration:0.91 Step:912 CStep:28533\n",
            "Episode:32 Time:16:01:55 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.312 Avg_Max_Q:0.000 Epsilon:0.56 Duration:0.96 Step:920 CStep:29454\n",
            "Episode:33 Time:16:01:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.55 Duration:0.81 Step:764 CStep:30219\n",
            "Episode:34 Time:16:01:58 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.294 Avg_Max_Q:0.000 Epsilon:0.53 Duration:1.24 Step:1184 CStep:31404\n",
            "Episode:35 Time:16:01:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.314 Avg_Max_Q:0.000 Epsilon:0.52 Duration:0.81 Step:783 CStep:32188\n",
            "Episode:36 Time:16:01:59 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.278 Avg_Max_Q:0.000 Epsilon:0.51 Duration:1.15 Step:1119 CStep:33308\n",
            "Episode:37 Time:16:02:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.297 Avg_Max_Q:0.000 Epsilon:0.50 Duration:0.98 Step:962 CStep:34271\n",
            "Episode:38 Time:16:02:01 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.289 Avg_Max_Q:0.000 Epsilon:0.49 Duration:1.00 Step:981 CStep:35253\n",
            "Episode:39 Time:16:02:02 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.282 Avg_Max_Q:0.000 Epsilon:0.48 Duration:0.88 Step:844 CStep:36098\n",
            "Episode:40 Time:16:02:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.48 Duration:0.87 Step:824 CStep:36923\n",
            "Episode:41 Time:16:02:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.317 Avg_Max_Q:0.000 Epsilon:0.47 Duration:0.90 Step:880 CStep:37804\n",
            "Episode:42 Time:16:02:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.46 Duration:0.92 Step:908 CStep:38713\n",
            "Episode:43 Time:16:02:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.349 Avg_Max_Q:0.000 Epsilon:0.45 Duration:0.95 Step:944 CStep:39658\n",
            "Episode:44 Time:16:02:07 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.341 Avg_Max_Q:0.000 Epsilon:0.45 Duration:0.91 Step:870 CStep:40529\n",
            "Episode:45 Time:16:02:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.356 Avg_Max_Q:0.000 Epsilon:0.44 Duration:0.86 Step:820 CStep:41350\n",
            "Episode:46 Time:16:02:09 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.348 Avg_Max_Q:0.000 Epsilon:0.43 Duration:1.02 Step:1008 CStep:42359\n",
            "Episode:47 Time:16:02:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.362 Avg_Max_Q:0.000 Epsilon:0.42 Duration:0.89 Step:872 CStep:43232\n",
            "Episode:48 Time:16:02:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.354 Avg_Max_Q:0.000 Epsilon:0.41 Duration:1.01 Step:960 CStep:44193\n",
            "Episode:49 Time:16:02:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.367 Avg_Max_Q:0.000 Epsilon:0.40 Duration:0.88 Step:871 CStep:45065\n",
            "Episode:50 Time:16:02:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.40 Duration:0.93 Step:901 CStep:45967\n",
            "Episode:51 Time:16:02:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.392 Avg_Max_Q:0.000 Epsilon:0.39 Duration:0.89 Step:871 CStep:46839\n",
            "Episode:52 Time:16:02:15 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.385 Avg_Max_Q:0.000 Epsilon:0.39 Duration:1.23 Step:1115 CStep:47955\n",
            "Episode:53 Time:16:02:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.396 Avg_Max_Q:0.000 Epsilon:0.38 Duration:0.94 Step:872 CStep:48828\n",
            "Episode:54 Time:16:02:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.407 Avg_Max_Q:0.000 Epsilon:0.37 Duration:0.97 Step:880 CStep:49709\n",
            "Episode:55 Time:16:02:17 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.36 Duration:0.86 Step:843 CStep:50553\n",
            "Episode:56 Time:16:02:19 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.393 Avg_Max_Q:0.000 Epsilon:0.36 Duration:1.17 Step:1172 CStep:51726\n",
            "Episode:57 Time:16:02:20 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.386 Avg_Max_Q:0.000 Epsilon:0.35 Duration:1.04 Step:1056 CStep:52783\n",
            "Episode:58 Time:16:02:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.397 Avg_Max_Q:0.000 Epsilon:0.34 Duration:0.89 Step:880 CStep:53664\n",
            "Episode:59 Time:16:02:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.407 Avg_Max_Q:0.000 Epsilon:0.34 Duration:0.82 Step:824 CStep:54489\n",
            "Episode:60 Time:16:02:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.417 Avg_Max_Q:0.000 Epsilon:0.33 Duration:0.81 Step:820 CStep:55310\n",
            "Episode:61 Time:16:02:23 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.426 Avg_Max_Q:0.000 Epsilon:0.32 Duration:0.91 Step:914 CStep:56225\n",
            "Episode:62 Time:16:02:24 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.435 Avg_Max_Q:0.000 Epsilon:0.32 Duration:1.10 Step:1114 CStep:57340\n",
            "Episode:63 Time:16:02:25 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.413 Avg_Max_Q:0.000 Epsilon:0.31 Duration:1.00 Step:1006 CStep:58347\n",
            "Episode:64 Time:16:02:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.422 Avg_Max_Q:0.000 Epsilon:0.30 Duration:0.76 Step:783 CStep:59131\n",
            "Episode:65 Time:16:02:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.431 Avg_Max_Q:0.000 Epsilon:0.30 Duration:2.28 Step:940 CStep:60072\n",
            "Episode:66 Time:16:02:29 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.424 Avg_Max_Q:0.000 Epsilon:0.30 Duration:0.93 Step:919 CStep:60992\n",
            "Episode:67 Time:16:02:30 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.388 Avg_Max_Q:0.000 Epsilon:0.29 Duration:1.11 Step:1133 CStep:62126\n",
            "Episode:68 Time:16:02:31 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.382 Avg_Max_Q:0.000 Epsilon:0.28 Duration:0.88 Step:899 CStep:63026\n",
            "Episode:69 Time:16:02:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.391 Avg_Max_Q:0.000 Epsilon:0.28 Duration:0.76 Step:783 CStep:63810\n",
            "Episode:70 Time:16:02:33 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.27 Duration:0.85 Step:852 CStep:64663\n",
            "Episode:71 Time:16:02:34 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.394 Avg_Max_Q:0.000 Epsilon:0.26 Duration:1.31 Step:1336 CStep:66000\n",
            "Episode:72 Time:16:02:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.403 Avg_Max_Q:0.000 Epsilon:0.26 Duration:0.75 Step:764 CStep:66765\n",
            "Episode:73 Time:16:02:36 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.384 Avg_Max_Q:0.000 Epsilon:0.26 Duration:1.06 Step:1082 CStep:67848\n",
            "Episode:74 Time:16:02:37 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.351 Avg_Max_Q:0.000 Epsilon:0.25 Duration:1.20 Step:1210 CStep:69059\n",
            "Episode:75 Time:16:02:38 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.25 Duration:0.84 Step:824 CStep:69884\n",
            "Episode:76 Time:16:02:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.368 Avg_Max_Q:0.000 Epsilon:0.24 Duration:0.76 Step:764 CStep:70649\n",
            "Episode:77 Time:16:02:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.377 Avg_Max_Q:0.000 Epsilon:0.24 Duration:0.87 Step:884 CStep:71534\n",
            "Episode:78 Time:16:02:41 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.372 Avg_Max_Q:0.000 Epsilon:0.23 Duration:1.01 Step:990 CStep:72525\n",
            "Episode:79 Time:16:02:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.23 Duration:0.89 Step:880 CStep:73406\n",
            "Episode:80 Time:16:02:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.387 Avg_Max_Q:0.000 Epsilon:0.22 Duration:0.84 Step:854 CStep:74261\n",
            "Episode:81 Time:16:02:43 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.22 Duration:1.00 Step:997 CStep:75259\n",
            "Episode:82 Time:16:02:44 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.366 Avg_Max_Q:0.000 Epsilon:0.22 Duration:0.89 Step:915 CStep:76175\n",
            "Episode:83 Time:16:02:45 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.361 Avg_Max_Q:0.000 Epsilon:0.21 Duration:0.82 Step:838 CStep:77014\n",
            "Episode:84 Time:16:02:46 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.369 Avg_Max_Q:0.000 Epsilon:0.21 Duration:0.79 Step:792 CStep:77807\n",
            "Episode:85 Time:16:02:47 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.341 Avg_Max_Q:0.000 Epsilon:0.21 Duration:1.03 Step:1054 CStep:78862\n",
            "Episode:86 Time:16:02:48 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.337 Avg_Max_Q:0.000 Epsilon:0.20 Duration:0.97 Step:959 CStep:79822\n",
            "Episode:87 Time:16:02:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.345 Avg_Max_Q:0.000 Epsilon:0.20 Duration:0.80 Step:792 CStep:80615\n",
            "Episode:88 Time:16:02:50 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.341 Avg_Max_Q:0.000 Epsilon:0.19 Duration:1.03 Step:1042 CStep:81658\n",
            "Episode:89 Time:16:02:51 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.348 Avg_Max_Q:0.000 Epsilon:0.19 Duration:0.89 Step:912 CStep:82571\n",
            "Episode:90 Time:16:02:52 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.344 Avg_Max_Q:0.000 Epsilon:0.19 Duration:1.03 Step:1048 CStep:83620\n",
            "Episode:91 Time:16:02:53 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.341 Avg_Max_Q:0.000 Epsilon:0.18 Duration:0.98 Step:986 CStep:84607\n",
            "Episode:92 Time:16:02:53 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.348 Avg_Max_Q:0.000 Epsilon:0.18 Duration:0.87 Step:885 CStep:85493\n",
            "Episode:93 Time:16:02:55 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.18 Duration:1.20 Step:1208 CStep:86702\n",
            "Episode:94 Time:16:02:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.17 Duration:0.95 Step:972 CStep:87675\n",
            "Episode:95 Time:16:02:57 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.347 Avg_Max_Q:0.000 Epsilon:0.17 Duration:0.88 Step:853 CStep:88529\n",
            "Episode:96 Time:16:02:57 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.354 Avg_Max_Q:0.000 Epsilon:0.17 Duration:0.81 Step:826 CStep:89356\n",
            "Episode:97 Time:16:02:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.361 Avg_Max_Q:0.000 Epsilon:0.16 Duration:0.90 Step:885 CStep:90242\n",
            "Episode:98 Time:16:02:59 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.357 Avg_Max_Q:0.000 Epsilon:0.16 Duration:0.88 Step:902 CStep:91145\n",
            "Episode:99 Time:16:03:00 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.354 Avg_Max_Q:0.000 Epsilon:0.16 Duration:0.98 Step:995 CStep:92141\n",
            "Episode:100 Time:16:03:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.16 Duration:0.84 Step:855 CStep:92997\n",
            "Episode:101 Time:16:03:02 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.15 Duration:0.88 Step:889 CStep:93887\n",
            "Episode:102 Time:16:03:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.15 Duration:0.80 Step:824 CStep:94712\n",
            "Episode:103 Time:16:03:03 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.15 Duration:0.83 Step:843 CStep:95556\n",
            "Episode:104 Time:16:03:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.14 Duration:0.80 Step:832 CStep:96389\n",
            "Episode:105 Time:16:03:05 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.14 Duration:0.99 Step:1021 CStep:97411\n",
            "Episode:106 Time:16:03:06 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.14 Duration:0.93 Step:949 CStep:98361\n",
            "Episode:107 Time:16:03:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.14 Duration:0.89 Step:900 CStep:99262\n",
            "Episode:108 Time:16:03:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.13 Duration:0.88 Step:884 CStep:100147\n",
            "Episode:109 Time:16:03:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.13 Duration:0.88 Step:884 CStep:101032\n",
            "Episode:110 Time:16:03:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.13 Duration:0.76 Step:764 CStep:101797\n",
            "Episode:111 Time:16:03:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.13 Duration:0.88 Step:898 CStep:102696\n",
            "Episode:112 Time:16:03:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.12 Duration:0.93 Step:932 CStep:103629\n",
            "Episode:113 Time:16:03:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.12 Duration:0.83 Step:820 CStep:104450\n",
            "Episode:114 Time:16:03:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.12 Duration:0.86 Step:882 CStep:105333\n",
            "Episode:115 Time:16:03:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.12 Duration:0.83 Step:820 CStep:106154\n",
            "Episode:116 Time:16:03:15 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.12 Duration:0.96 Step:972 CStep:107127\n",
            "Episode:117 Time:16:03:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.11 Duration:0.94 Step:948 CStep:108076\n",
            "Episode:118 Time:16:03:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.11 Duration:0.78 Step:792 CStep:108869\n",
            "Episode:119 Time:16:03:18 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.11 Duration:0.88 Step:927 CStep:109797\n",
            "Episode:120 Time:16:03:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.11 Duration:0.92 Step:957 CStep:110755\n",
            "Episode:121 Time:16:03:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.11 Duration:0.92 Step:974 CStep:111730\n",
            "Episode:122 Time:16:03:20 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.10 Duration:1.05 Step:1107 CStep:112838\n",
            "Episode:123 Time:16:03:21 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.10 Duration:0.88 Step:951 CStep:113790\n",
            "Episode:124 Time:16:03:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.10 Duration:0.83 Step:880 CStep:114671\n",
            "Episode:125 Time:16:03:23 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.10 Duration:1.08 Step:1155 CStep:115827\n",
            "Episode:126 Time:16:03:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.10 Duration:1.94 Step:792 CStep:116620\n",
            "Episode:127 Time:16:03:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.09 Duration:1.08 Step:1060 CStep:117681\n",
            "Episode:128 Time:16:03:27 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.09 Duration:1.00 Step:1020 CStep:118702\n",
            "Episode:129 Time:16:03:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.09 Duration:0.86 Step:874 CStep:119577\n",
            "Episode:130 Time:16:03:29 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.09 Duration:0.94 Step:930 CStep:120508\n",
            "Episode:131 Time:16:03:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.09 Duration:0.75 Step:764 CStep:121273\n",
            "Episode:132 Time:16:03:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.09 Duration:0.82 Step:840 CStep:122114\n",
            "Episode:133 Time:16:03:32 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.08 Duration:1.27 Step:1255 CStep:123370\n",
            "Episode:134 Time:16:03:33 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.75 Step:764 CStep:124135\n",
            "Episode:135 Time:16:03:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.94 Step:930 CStep:125066\n",
            "Episode:136 Time:16:03:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.86 Step:854 CStep:125921\n",
            "Episode:137 Time:16:03:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.75 Step:764 CStep:126686\n",
            "Episode:138 Time:16:03:36 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.89 Step:911 CStep:127598\n",
            "Episode:139 Time:16:03:37 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.08 Duration:0.81 Step:821 CStep:128420\n",
            "Episode:140 Time:16:03:38 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.86 Step:873 CStep:129294\n",
            "Episode:141 Time:16:03:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.90 Step:914 CStep:130209\n",
            "Episode:142 Time:16:03:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.82 Step:812 CStep:131022\n",
            "Episode:143 Time:16:03:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.86 Step:854 CStep:131877\n",
            "Episode:144 Time:16:03:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.89 Step:912 CStep:132790\n",
            "Episode:145 Time:16:03:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.85 Step:852 CStep:133643\n",
            "Episode:146 Time:16:03:43 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.98 Step:995 CStep:134639\n",
            "Episode:147 Time:16:03:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.07 Duration:0.76 Step:764 CStep:135404\n",
            "Episode:148 Time:16:03:45 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.99 Step:1005 CStep:136410\n",
            "Episode:149 Time:16:03:46 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.87 Step:883 CStep:137294\n",
            "Episode:150 Time:16:03:47 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.06 Duration:1.06 Step:1079 CStep:138374\n",
            "Episode:151 Time:16:03:48 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.06 Duration:1.02 Step:1027 CStep:139402\n",
            "Episode:152 Time:16:03:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.92 Step:914 CStep:140317\n",
            "Episode:153 Time:16:03:50 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.78 Step:783 CStep:141101\n",
            "Episode:154 Time:16:03:50 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.84 Step:852 CStep:141954\n",
            "Episode:155 Time:16:03:51 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.88 Step:903 CStep:142858\n",
            "Episode:156 Time:16:03:52 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.06 Duration:0.87 Step:882 CStep:143741\n",
            "Episode:157 Time:16:03:53 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:1.06 Step:1087 CStep:144829\n",
            "Episode:158 Time:16:03:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.91 Step:929 CStep:145759\n",
            "Episode:159 Time:16:03:55 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.82 Step:824 CStep:146584\n",
            "Episode:160 Time:16:03:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.87 Step:880 CStep:147465\n",
            "Episode:161 Time:16:03:57 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.91 Step:922 CStep:148388\n",
            "Episode:162 Time:16:03:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.85 Step:870 CStep:149259\n",
            "Episode:163 Time:16:03:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.76 Step:764 CStep:150024\n",
            "Episode:164 Time:16:03:59 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:1.05 Step:1035 CStep:151060\n",
            "Episode:165 Time:16:04:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.82 Step:821 CStep:151882\n",
            "Episode:166 Time:16:04:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.81 Step:824 CStep:152707\n",
            "Episode:167 Time:16:04:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.05 Duration:0.88 Step:886 CStep:153594\n",
            "Episode:168 Time:16:04:03 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.99 Step:999 CStep:154594\n",
            "Episode:169 Time:16:04:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.86 Step:872 CStep:155467\n",
            "Episode:170 Time:16:04:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.77 Step:792 CStep:156260\n",
            "Episode:171 Time:16:04:06 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.04 Duration:1.02 Step:1008 CStep:157269\n",
            "Episode:172 Time:16:04:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.90 Step:914 CStep:158184\n",
            "Episode:173 Time:16:04:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.82 Step:854 CStep:159039\n",
            "Episode:174 Time:16:04:09 Reward:-17.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.04 Duration:1.26 Step:1294 CStep:160334\n",
            "Episode:175 Time:16:04:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.76 Step:764 CStep:161099\n",
            "Episode:176 Time:16:04:10 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.85 Step:842 CStep:161942\n",
            "Episode:177 Time:16:04:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.98 Step:977 CStep:162920\n",
            "Episode:178 Time:16:04:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.04 Duration:1.07 Step:1062 CStep:163983\n",
            "Episode:179 Time:16:04:13 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.92 Step:921 CStep:164905\n",
            "Episode:180 Time:16:04:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.04 Duration:0.87 Step:884 CStep:165790\n",
            "Episode:181 Time:16:04:15 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:811 CStep:166602\n",
            "Episode:182 Time:16:04:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.08 Step:1120 CStep:167723\n",
            "Episode:183 Time:16:04:17 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:905 CStep:168629\n",
            "Episode:184 Time:16:04:18 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:900 CStep:169530\n",
            "Episode:185 Time:16:04:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:987 CStep:170518\n",
            "Episode:186 Time:16:04:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:885 CStep:171404\n",
            "Episode:187 Time:16:04:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:891 CStep:172296\n",
            "Episode:188 Time:16:04:21 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:979 CStep:173276\n",
            "Episode:189 Time:16:04:22 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:958 CStep:174235\n",
            "Episode:190 Time:16:04:23 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:845 CStep:175081\n",
            "Episode:191 Time:16:04:24 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:948 CStep:176030\n",
            "Episode:192 Time:16:04:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:176795\n",
            "Episode:193 Time:16:04:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:950 CStep:177746\n",
            "Episode:194 Time:16:04:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1025 CStep:178772\n",
            "Episode:195 Time:16:04:27 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:944 CStep:179717\n",
            "Episode:196 Time:16:04:28 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.530 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:870 CStep:180588\n",
            "Episode:197 Time:16:04:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.530 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:793 CStep:181382\n",
            "Episode:198 Time:16:04:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1019 CStep:182402\n",
            "Episode:199 Time:16:04:31 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:870 CStep:183273\n",
            "Episode:200 Time:16:04:32 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.530 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1065 CStep:184339\n",
            "Episode:201 Time:16:04:33 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.530 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:947 CStep:185287\n",
            "Episode:202 Time:16:04:34 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:962 CStep:186250\n",
            "Episode:203 Time:16:04:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.530 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:853 CStep:187104\n",
            "Episode:204 Time:16:04:35 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:870 CStep:187975\n",
            "Episode:205 Time:16:04:36 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:959 CStep:188935\n",
            "Episode:206 Time:16:04:37 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:842 CStep:189778\n",
            "Episode:207 Time:16:04:38 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.05 Step:1136 CStep:190915\n",
            "Episode:208 Time:16:04:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:903 CStep:191819\n",
            "Episode:209 Time:16:04:40 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1019 CStep:192839\n",
            "Episode:210 Time:16:04:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:193604\n",
            "Episode:211 Time:16:04:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:852 CStep:194457\n",
            "Episode:212 Time:16:04:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.520 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:914 CStep:195372\n",
            "Episode:213 Time:16:04:43 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.510 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:1006 CStep:196379\n",
            "Episode:214 Time:16:04:44 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:995 CStep:197375\n",
            "Episode:215 Time:16:04:45 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:960 CStep:198336\n",
            "Episode:216 Time:16:04:46 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.11 Step:1172 CStep:199509\n",
            "Episode:217 Time:16:04:48 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.03 Duration:2.32 Step:942 CStep:200452\n",
            "Episode:218 Time:16:04:50 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.32 Step:1291 CStep:201744\n",
            "Episode:219 Time:16:04:51 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:932 CStep:202677\n",
            "Episode:220 Time:16:04:52 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.15 Step:1146 CStep:203824\n",
            "Episode:221 Time:16:04:53 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1035 CStep:204860\n",
            "Episode:222 Time:16:04:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:944 CStep:205805\n",
            "Episode:223 Time:16:04:55 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:843 CStep:206649\n",
            "Episode:224 Time:16:04:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:852 CStep:207502\n",
            "Episode:225 Time:16:04:56 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:902 CStep:208405\n",
            "Episode:226 Time:16:04:57 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:820 CStep:209226\n",
            "Episode:227 Time:16:04:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:852 CStep:210079\n",
            "Episode:228 Time:16:04:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:792 CStep:210872\n",
            "Episode:229 Time:16:05:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:764 CStep:211637\n",
            "Episode:230 Time:16:05:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:904 CStep:212542\n",
            "Episode:231 Time:16:05:01 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:895 CStep:213438\n",
            "Episode:232 Time:16:05:02 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1007 CStep:214446\n",
            "Episode:233 Time:16:05:03 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:995 CStep:215442\n",
            "Episode:234 Time:16:05:04 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1035 CStep:216478\n",
            "Episode:235 Time:16:05:06 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.08 Step:1102 CStep:217581\n",
            "Episode:236 Time:16:05:06 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:902 CStep:218484\n",
            "Episode:237 Time:16:05:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:974 CStep:219459\n",
            "Episode:238 Time:16:05:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:913 CStep:220373\n",
            "Episode:239 Time:16:05:09 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:922 CStep:221296\n",
            "Episode:240 Time:16:05:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:222061\n",
            "Episode:241 Time:16:05:11 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.11 Step:1129 CStep:223191\n",
            "Episode:242 Time:16:05:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:792 CStep:223984\n",
            "Episode:243 Time:16:05:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:224749\n",
            "Episode:244 Time:16:05:14 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.15 Step:1187 CStep:225937\n",
            "Episode:245 Time:16:05:15 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.07 Step:1104 CStep:227042\n",
            "Episode:246 Time:16:05:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:878 CStep:227921\n",
            "Episode:247 Time:16:05:17 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.98 Step:1000 CStep:228922\n",
            "Episode:248 Time:16:05:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.320 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:792 CStep:229715\n",
            "Episode:249 Time:16:05:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.320 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:844 CStep:230560\n",
            "Episode:250 Time:16:05:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:964 CStep:231525\n",
            "Episode:251 Time:16:05:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:852 CStep:232378\n",
            "Episode:252 Time:16:05:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:932 CStep:233311\n",
            "Episode:253 Time:16:05:22 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.320 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.15 Step:1162 CStep:234474\n",
            "Episode:254 Time:16:05:23 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:957 CStep:235432\n",
            "Episode:255 Time:16:05:24 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:944 CStep:236377\n",
            "Episode:256 Time:16:05:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:820 CStep:237198\n",
            "Episode:257 Time:16:05:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:901 CStep:238100\n",
            "Episode:258 Time:16:05:27 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:843 CStep:238944\n",
            "Episode:259 Time:16:05:28 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.25 Step:1275 CStep:240220\n",
            "Episode:260 Time:16:05:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:824 CStep:241045\n",
            "Episode:261 Time:16:05:30 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:930 CStep:241976\n",
            "Episode:262 Time:16:05:30 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:861 CStep:242838\n",
            "Episode:263 Time:16:05:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:912 CStep:243751\n",
            "Episode:264 Time:16:05:32 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.260 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:996 CStep:244748\n",
            "Episode:265 Time:16:05:33 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1033 CStep:245782\n",
            "Episode:266 Time:16:05:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:845 CStep:246628\n",
            "Episode:267 Time:16:05:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:811 CStep:247440\n",
            "Episode:268 Time:16:05:36 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:248205\n",
            "Episode:269 Time:16:05:37 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.08 Step:1084 CStep:249290\n",
            "Episode:270 Time:16:05:38 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.73 Step:764 CStep:250055\n",
            "Episode:271 Time:16:05:38 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.260 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:895 CStep:250951\n",
            "Episode:272 Time:16:05:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.260 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:852 CStep:251804\n",
            "Episode:273 Time:16:05:40 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:930 CStep:252735\n",
            "Episode:274 Time:16:05:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:811 CStep:253547\n",
            "Episode:275 Time:16:05:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:942 CStep:254490\n",
            "Episode:276 Time:16:05:43 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:916 CStep:255407\n",
            "Episode:277 Time:16:05:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:995 CStep:256403\n",
            "Episode:278 Time:16:05:45 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1087 CStep:257491\n",
            "Episode:279 Time:16:05:46 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.260 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:1043 CStep:258535\n",
            "Episode:280 Time:16:05:47 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1065 CStep:259601\n",
            "Episode:281 Time:16:05:48 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:1036 CStep:260638\n",
            "Episode:282 Time:16:05:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:975 CStep:261614\n",
            "Episode:283 Time:16:05:49 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:902 CStep:262517\n",
            "Episode:284 Time:16:05:50 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:962 CStep:263480\n",
            "Episode:285 Time:16:05:51 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:880 CStep:264361\n",
            "Episode:286 Time:16:05:52 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1021 CStep:265383\n",
            "Episode:287 Time:16:05:53 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.220 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1019 CStep:266403\n",
            "Episode:288 Time:16:05:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:871 CStep:267275\n",
            "Episode:289 Time:16:05:55 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.220 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.98 Step:1056 CStep:268332\n",
            "Episode:290 Time:16:05:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.220 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:886 CStep:269219\n",
            "Episode:291 Time:16:05:57 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1065 CStep:270285\n",
            "Episode:292 Time:16:05:57 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.200 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:889 CStep:271175\n",
            "Episode:293 Time:16:05:58 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.190 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1079 CStep:272255\n",
            "Episode:294 Time:16:05:59 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.170 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:981 CStep:273237\n",
            "Episode:295 Time:16:06:00 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.160 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:885 CStep:274123\n",
            "Episode:296 Time:16:06:01 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.150 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:996 CStep:275120\n",
            "Episode:297 Time:16:06:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.150 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:848 CStep:275969\n",
            "Episode:298 Time:16:06:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.150 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:974 CStep:276944\n",
            "Episode:299 Time:16:06:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.160 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:914 CStep:277859\n",
            "Episode:300 Time:16:06:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.170 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:999 CStep:278859\n",
            "Episode:301 Time:16:06:06 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.170 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.98 Step:1043 CStep:279903\n",
            "Episode:302 Time:16:06:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.180 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:822 CStep:280726\n",
            "Episode:303 Time:16:06:07 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.170 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:962 CStep:281689\n",
            "Episode:304 Time:16:06:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.180 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:811 CStep:282501\n",
            "Episode:305 Time:16:06:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.190 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:812 CStep:283314\n",
            "Episode:306 Time:16:06:10 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.190 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:838 CStep:284153\n",
            "Episode:307 Time:16:06:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:825 CStep:284979\n",
            "Episode:308 Time:16:06:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:783 CStep:285763\n",
            "Episode:309 Time:16:06:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:899 CStep:286663\n",
            "Episode:310 Time:16:06:13 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.220 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:896 CStep:287560\n",
            "Episode:311 Time:16:06:14 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:899 CStep:288460\n",
            "Episode:312 Time:16:06:15 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.200 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:1037 CStep:289498\n",
            "Episode:313 Time:16:06:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.200 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1009 CStep:290508\n",
            "Episode:314 Time:16:06:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:291273\n",
            "Episode:315 Time:16:06:17 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.210 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:932 CStep:292206\n",
            "Episode:316 Time:16:06:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:852 CStep:293059\n",
            "Episode:317 Time:16:06:19 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.220 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:908 CStep:293968\n",
            "Episode:318 Time:16:06:20 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:900 CStep:294869\n",
            "Episode:319 Time:16:06:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:820 CStep:295690\n",
            "Episode:320 Time:16:06:22 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1072 CStep:296763\n",
            "Episode:321 Time:16:06:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.260 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:811 CStep:297575\n",
            "Episode:322 Time:16:06:23 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:965 CStep:298541\n",
            "Episode:323 Time:16:06:24 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:997 CStep:299539\n",
            "Episode:324 Time:16:06:25 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:947 CStep:300487\n",
            "Episode:325 Time:16:06:26 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:921 CStep:301409\n",
            "Episode:326 Time:16:06:27 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:905 CStep:302315\n",
            "Episode:327 Time:16:06:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:792 CStep:303108\n",
            "Episode:328 Time:16:06:28 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.73 Step:792 CStep:303901\n",
            "Episode:329 Time:16:06:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:854 CStep:304756\n",
            "Episode:330 Time:16:06:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:826 CStep:305583\n",
            "Episode:331 Time:16:06:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.74 Step:783 CStep:306367\n",
            "Episode:332 Time:16:06:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:307132\n",
            "Episode:333 Time:16:06:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:824 CStep:307957\n",
            "Episode:334 Time:16:06:33 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:932 CStep:308890\n",
            "Episode:335 Time:16:06:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.74 Step:764 CStep:309655\n",
            "Episode:336 Time:16:06:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:973 CStep:310629\n",
            "Episode:337 Time:16:06:36 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:992 CStep:311622\n",
            "Episode:338 Time:16:06:37 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:852 CStep:312475\n",
            "Episode:339 Time:16:06:37 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:313240\n",
            "Episode:340 Time:16:06:38 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.280 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:932 CStep:314173\n",
            "Episode:341 Time:16:06:39 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.07 Step:1148 CStep:315322\n",
            "Episode:342 Time:16:06:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:824 CStep:316147\n",
            "Episode:343 Time:16:06:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.270 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:853 CStep:317001\n",
            "Episode:344 Time:16:06:43 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.290 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.95 Step:794 CStep:317796\n",
            "Episode:345 Time:16:06:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:820 CStep:318617\n",
            "Episode:346 Time:16:06:45 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1014 CStep:319632\n",
            "Episode:347 Time:16:06:46 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.320 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1000 CStep:320633\n",
            "Episode:348 Time:16:06:47 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:981 CStep:321615\n",
            "Episode:349 Time:16:06:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:821 CStep:322437\n",
            "Episode:350 Time:16:06:48 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1000 CStep:323438\n",
            "Episode:351 Time:16:06:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1001 CStep:324440\n",
            "Episode:352 Time:16:06:50 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:988 CStep:325429\n",
            "Episode:353 Time:16:06:51 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.310 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:984 CStep:326414\n",
            "Episode:354 Time:16:06:52 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:852 CStep:327267\n",
            "Episode:355 Time:16:06:53 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1003 CStep:328271\n",
            "Episode:356 Time:16:06:54 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.06 Step:1065 CStep:329337\n",
            "Episode:357 Time:16:06:55 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:852 CStep:330190\n",
            "Episode:358 Time:16:06:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:811 CStep:331002\n",
            "Episode:359 Time:16:06:57 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.00 Step:1029 CStep:332032\n",
            "Episode:360 Time:16:06:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:824 CStep:332857\n",
            "Episode:361 Time:16:06:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:764 CStep:333622\n",
            "Episode:362 Time:16:06:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:950 CStep:334573\n",
            "Episode:363 Time:16:07:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:974 CStep:335548\n",
            "Episode:364 Time:16:07:02 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.340 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.26 Step:1289 CStep:336838\n",
            "Episode:365 Time:16:07:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:960 CStep:337799\n",
            "Episode:366 Time:16:07:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:824 CStep:338624\n",
            "Episode:367 Time:16:07:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:884 CStep:339509\n",
            "Episode:368 Time:16:07:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:783 CStep:340293\n",
            "Episode:369 Time:16:07:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:854 CStep:341148\n",
            "Episode:370 Time:16:07:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:792 CStep:341941\n",
            "Episode:371 Time:16:07:08 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.16 Step:1170 CStep:343112\n",
            "Episode:372 Time:16:07:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:801 CStep:343914\n",
            "Episode:373 Time:16:07:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1007 CStep:344922\n",
            "Episode:374 Time:16:07:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.09 Step:1117 CStep:346040\n",
            "Episode:375 Time:16:07:12 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.03 Step:1061 CStep:347102\n",
            "Episode:376 Time:16:07:13 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.98 Step:982 CStep:348085\n",
            "Episode:377 Time:16:07:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:792 CStep:348878\n",
            "Episode:378 Time:16:07:15 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:963 CStep:349842\n",
            "Episode:379 Time:16:07:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:923 CStep:350766\n",
            "Episode:380 Time:16:07:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:873 CStep:351640\n",
            "Episode:381 Time:16:07:18 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.11 Step:1142 CStep:352783\n",
            "Episode:382 Time:16:07:19 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.09 Step:1098 CStep:353882\n",
            "Episode:383 Time:16:07:19 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:844 CStep:354727\n",
            "Episode:384 Time:16:07:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:941 CStep:355669\n",
            "Episode:385 Time:16:07:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:903 CStep:356573\n",
            "Episode:386 Time:16:07:22 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.06 Step:1056 CStep:357630\n",
            "Episode:387 Time:16:07:23 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:871 CStep:358502\n",
            "Episode:388 Time:16:07:24 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:842 CStep:359345\n",
            "Episode:389 Time:16:07:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.02 Step:1024 CStep:360370\n",
            "Episode:390 Time:16:07:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:361135\n",
            "Episode:391 Time:16:07:27 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:930 CStep:362066\n",
            "Episode:392 Time:16:07:27 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:794 CStep:362861\n",
            "Episode:393 Time:16:07:28 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.92 Step:938 CStep:363800\n",
            "Episode:394 Time:16:07:29 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:843 CStep:364644\n",
            "Episode:395 Time:16:07:30 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:917 CStep:365562\n",
            "Episode:396 Time:16:07:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:914 CStep:366477\n",
            "Episode:397 Time:16:07:32 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:937 CStep:367415\n",
            "Episode:398 Time:16:07:33 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:993 CStep:368409\n",
            "Episode:399 Time:16:07:34 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:843 CStep:369253\n",
            "Episode:400 Time:16:07:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:947 CStep:370201\n",
            "Episode:401 Time:16:07:36 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.04 Step:1079 CStep:371281\n",
            "Episode:402 Time:16:07:36 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:871 CStep:372153\n",
            "Episode:403 Time:16:07:38 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.01 Step:1069 CStep:373223\n",
            "Episode:404 Time:16:07:38 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:919 CStep:374143\n",
            "Episode:405 Time:16:07:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:884 CStep:375028\n",
            "Episode:406 Time:16:07:40 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:832 CStep:375861\n",
            "Episode:407 Time:16:07:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:811 CStep:376673\n",
            "Episode:408 Time:16:07:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:1008 CStep:377682\n",
            "Episode:409 Time:16:07:43 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.06 Step:1127 CStep:378810\n",
            "Episode:410 Time:16:07:44 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:958 CStep:379769\n",
            "Episode:411 Time:16:07:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:824 CStep:380594\n",
            "Episode:412 Time:16:07:45 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.98 Step:1002 CStep:381597\n",
            "Episode:413 Time:16:07:47 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.07 Step:1132 CStep:382730\n",
            "Episode:414 Time:16:07:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:764 CStep:383495\n",
            "Episode:415 Time:16:07:48 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.07 Step:1096 CStep:384592\n",
            "Episode:416 Time:16:07:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:385385\n",
            "Episode:417 Time:16:07:50 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:1006 CStep:386392\n",
            "Episode:418 Time:16:07:51 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:843 CStep:387236\n",
            "Episode:419 Time:16:07:52 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:388001\n",
            "Episode:420 Time:16:07:52 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:870 CStep:388872\n",
            "Episode:421 Time:16:07:53 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:961 CStep:389834\n",
            "Episode:422 Time:16:07:55 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.13 Step:1138 CStep:390973\n",
            "Episode:423 Time:16:07:55 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:1008 CStep:391982\n",
            "Episode:424 Time:16:07:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:794 CStep:392777\n",
            "Episode:425 Time:16:07:57 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:921 CStep:393699\n",
            "Episode:426 Time:16:07:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:824 CStep:394524\n",
            "Episode:427 Time:16:07:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.74 Step:792 CStep:395317\n",
            "Episode:428 Time:16:07:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:821 CStep:396139\n",
            "Episode:429 Time:16:08:00 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:878 CStep:397018\n",
            "Episode:430 Time:16:08:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1051 CStep:398070\n",
            "Episode:431 Time:16:08:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:933 CStep:399004\n",
            "Episode:432 Time:16:08:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:931 CStep:399936\n",
            "Episode:433 Time:16:08:04 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.04 Step:1086 CStep:401023\n",
            "Episode:434 Time:16:08:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:843 CStep:401867\n",
            "Episode:435 Time:16:08:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:852 CStep:402720\n",
            "Episode:436 Time:16:08:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.360 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:792 CStep:403513\n",
            "Episode:437 Time:16:08:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:792 CStep:404306\n",
            "Episode:438 Time:16:08:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:940 CStep:405247\n",
            "Episode:439 Time:16:08:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:824 CStep:406072\n",
            "Episode:440 Time:16:08:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:406837\n",
            "Episode:441 Time:16:08:10 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:905 CStep:407743\n",
            "Episode:442 Time:16:08:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:951 CStep:408695\n",
            "Episode:443 Time:16:08:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:1039 CStep:409735\n",
            "Episode:444 Time:16:08:13 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.84 Step:890 CStep:410626\n",
            "Episode:445 Time:16:08:14 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:903 CStep:411530\n",
            "Episode:446 Time:16:08:15 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:917 CStep:412448\n",
            "Episode:447 Time:16:08:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:930 CStep:413379\n",
            "Episode:448 Time:16:08:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:852 CStep:414232\n",
            "Episode:449 Time:16:08:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.74 Step:764 CStep:414997\n",
            "Episode:450 Time:16:08:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:820 CStep:415818\n",
            "Episode:451 Time:16:08:19 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.16 Step:1203 CStep:417022\n",
            "Episode:452 Time:16:08:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:943 CStep:417966\n",
            "Episode:453 Time:16:08:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:824 CStep:418791\n",
            "Episode:454 Time:16:08:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:852 CStep:419644\n",
            "Episode:455 Time:16:08:23 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:947 CStep:420592\n",
            "Episode:456 Time:16:08:24 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.07 Step:1148 CStep:421741\n",
            "Episode:457 Time:16:08:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:852 CStep:422594\n",
            "Episode:458 Time:16:08:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:423387\n",
            "Episode:459 Time:16:08:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:824 CStep:424212\n",
            "Episode:460 Time:16:08:27 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.05 Step:1097 CStep:425310\n",
            "Episode:461 Time:16:08:28 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.02 Step:1089 CStep:426400\n",
            "Episode:462 Time:16:08:29 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:427193\n",
            "Episode:463 Time:16:08:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.71 Step:764 CStep:427958\n",
            "Episode:464 Time:16:08:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:914 CStep:428873\n",
            "Episode:465 Time:16:08:31 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:912 CStep:429786\n",
            "Episode:466 Time:16:08:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:825 CStep:430612\n",
            "Episode:467 Time:16:08:33 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:792 CStep:431405\n",
            "Episode:468 Time:16:08:34 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.03 Step:1055 CStep:432461\n",
            "Episode:469 Time:16:08:35 Reward:-17.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.13 Step:1225 CStep:433687\n",
            "Episode:470 Time:16:08:36 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:852 CStep:434540\n",
            "Episode:471 Time:16:08:37 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:978 CStep:435519\n",
            "Episode:472 Time:16:08:38 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:794 CStep:436314\n",
            "Episode:473 Time:16:08:38 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.370 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:912 CStep:437227\n",
            "Episode:474 Time:16:08:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:912 CStep:438140\n",
            "Episode:475 Time:16:08:40 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.380 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:921 CStep:439062\n",
            "Episode:476 Time:16:08:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.81 Step:866 CStep:439929\n",
            "Episode:477 Time:16:08:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.95 Step:1006 CStep:440936\n",
            "Episode:478 Time:16:08:43 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:441729\n",
            "Episode:479 Time:16:08:44 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.96 Step:992 CStep:442722\n",
            "Episode:480 Time:16:08:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.390 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:845 CStep:443568\n",
            "Episode:481 Time:16:08:45 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.87 Step:932 CStep:444501\n",
            "Episode:482 Time:16:08:46 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1053 CStep:445555\n",
            "Episode:483 Time:16:08:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.73 Step:783 CStep:446339\n",
            "Episode:484 Time:16:08:48 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:886 CStep:447226\n",
            "Episode:485 Time:16:08:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:854 CStep:448081\n",
            "Episode:486 Time:16:08:50 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:826 CStep:448908\n",
            "Episode:487 Time:16:08:51 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.12 Step:1212 CStep:450121\n",
            "Episode:488 Time:16:08:51 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.77 Step:820 CStep:450942\n",
            "Episode:489 Time:16:08:52 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:451735\n",
            "Episode:490 Time:16:08:53 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.76 Step:792 CStep:452528\n",
            "Episode:491 Time:16:08:54 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.89 Step:936 CStep:453465\n",
            "Episode:492 Time:16:08:55 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:844 CStep:454310\n",
            "Episode:493 Time:16:08:55 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.83 Step:884 CStep:455195\n",
            "Episode:494 Time:16:08:56 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:986 CStep:456182\n",
            "Episode:495 Time:16:08:57 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:872 CStep:457055\n",
            "Episode:496 Time:16:08:58 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:987 CStep:458043\n",
            "Episode:497 Time:16:08:59 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.86 Step:920 CStep:458964\n",
            "Episode:498 Time:16:09:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.82 Step:872 CStep:459837\n",
            "Episode:499 Time:16:09:01 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.88 Step:949 CStep:460787\n",
            "Episode:500 Time:16:09:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:843 CStep:461631\n",
            "Episode:501 Time:16:09:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.78 Step:824 CStep:462456\n",
            "Episode:502 Time:16:09:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.80 Step:825 CStep:463282\n",
            "Episode:503 Time:16:09:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.480 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.74 Step:764 CStep:464047\n",
            "Episode:504 Time:16:09:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.490 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.75 Step:792 CStep:464840\n",
            "Episode:505 Time:16:09:06 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.99 Step:1057 CStep:465898\n",
            "Episode:506 Time:16:09:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.470 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.79 Step:840 CStep:466739\n",
            "Episode:507 Time:16:09:07 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.460 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.93 Step:981 CStep:467721\n",
            "Episode:508 Time:16:09:08 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:949 CStep:468671\n",
            "Episode:509 Time:16:09:09 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.450 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.90 Step:960 CStep:469632\n",
            "Episode:510 Time:16:09:10 Reward:-18.00 Loss:0.00 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.97 Step:1029 CStep:470662\n",
            "Episode:511 Time:16:09:11 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.85 Step:902 CStep:471565\n",
            "Episode:512 Time:16:09:12 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:1.06 Step:1132 CStep:472698\n",
            "Episode:513 Time:16:09:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:2.18 Step:900 CStep:473599\n",
            "Episode:514 Time:16:09:15 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.410 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.91 Step:897 CStep:474497\n",
            "Episode:515 Time:16:09:16 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.420 Avg_Max_Q:0.000 Epsilon:0.03 Duration:0.94 Step:948 CStep:475446\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-60716c446972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Act\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Observe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/atari/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Render rgb array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jXpbO9ezHZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}